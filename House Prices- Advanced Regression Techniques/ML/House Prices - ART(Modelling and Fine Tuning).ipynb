{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split, cross_val_score, StratifiedShuffleSplit\n",
    "from sklearn.metrics import  mean_squared_log_error\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Variables for grid search\n",
    "n_splits = 3\n",
    "n_jobs = 3\n",
    "\n",
    "max_depth_min = 3\n",
    "max_depth_max = 15\n",
    "n_estimator_min = 100\n",
    "n_estimator_max = 200\n",
    "\n",
    "test_size =0.2\n",
    "random_state = 1986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_File = 'train.csv'\n",
    "test_File = 'test.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_File)\n",
    "df_test = pd.read_csv(test_File)\n",
    "df_test['SalePrice'] = 0\n",
    "df_concat = pd.concat([df_train,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSSubClass MSZoning  LotFrontage  LotArea Street         Alley LotShape  \\\n",
       "0         60       RL         65.0   8450.0   Pave  NotAvailable      Reg   \n",
       "1         20       RL         80.0   9600.0   Pave  NotAvailable      Reg   \n",
       "2         60       RL         68.0  11250.0   Pave  NotAvailable      IR1   \n",
       "3         70       RL         60.0   9550.0   Pave  NotAvailable      IR1   \n",
       "4         60       RL         84.0  14260.0   Pave  NotAvailable      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig    ...     PoolArea        PoolQC  \\\n",
       "0         Lvl    AllPub    Inside    ...          0.0  NotAvailable   \n",
       "1         Lvl    AllPub       FR2    ...          0.0  NotAvailable   \n",
       "2         Lvl    AllPub    Inside    ...          0.0  NotAvailable   \n",
       "3         Lvl    AllPub    Corner    ...          0.0  NotAvailable   \n",
       "4         Lvl    AllPub       FR2    ...          0.0  NotAvailable   \n",
       "\n",
       "          Fence   MiscFeature MiscVal MoSold  YrSold SaleType  SaleCondition  \\\n",
       "0  NotAvailable  NotAvailable     0.0      2  2008.0       WD         Normal   \n",
       "1  NotAvailable  NotAvailable     0.0      5  2007.0       WD         Normal   \n",
       "2  NotAvailable  NotAvailable     0.0      9  2008.0       WD         Normal   \n",
       "3  NotAvailable  NotAvailable     0.0      2  2006.0       WD        Abnorml   \n",
       "4  NotAvailable  NotAvailable     0.0     12  2008.0       WD         Normal   \n",
       "\n",
       "   SalePrice  \n",
       "0   208500.0  \n",
       "1   181500.0  \n",
       "2   223500.0  \n",
       "3   140000.0  \n",
       "4   250000.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def giveMeWrangledData(df, testFile=False, log=False):\n",
    "    \n",
    "    \n",
    "    df = df.drop(['Id', 'GarageYrBlt','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF'],axis=1)\n",
    "    \n",
    "    df['LotFrontage'] =df.LotFrontage.fillna(df.LotFrontage.mode()[0])\n",
    "    df['MasVnrArea']=df.MasVnrArea.fillna(0.0)\n",
    "    df['TotalBsmtSF'] = df.TotalBsmtSF.fillna(0)\n",
    "    df['BsmtFullBath'] = df.BsmtFullBath.fillna(0)\n",
    "    df['BsmtHalfBath'] = df.BsmtHalfBath.fillna(0)\n",
    "    df['GarageCars'] = df.GarageCars.fillna(0)\n",
    "    df['GarageArea'] = df.GarageArea.fillna(0)\n",
    "    \n",
    "    #convert data type\n",
    "    #we are being little lineant to give int64 for YearBuilt, YrSold but those guys are going to be box-coxed \n",
    "    #so let them at least enjoy the bigger size for now\n",
    "    int64_variables = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', \\\n",
    "                     'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', \\\n",
    "                     'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\\\n",
    "                     'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', \\\n",
    "                     'PoolArea', 'MiscVal', 'YrSold', 'SalePrice']\n",
    "    \n",
    "    #if testFile:\n",
    "    #    int64_variables.remove('SalePrice')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    for c in int64_variables:\n",
    "        if log:\n",
    "            print(\"Changing the data type for :\", c)\n",
    "        #df[c] = df[c].astype(np.int64)\n",
    "        df[c] = df[c].astype(np.float64)\n",
    "        \n",
    "    int_to_categorical_variables = ['MSSubClass', 'OverallQual', 'OverallCond', 'FireplaceQu', 'MoSold']\n",
    "    for c in int_to_categorical_variables:\n",
    "        df[c] = df[c].astype(str)\n",
    "        \n",
    "    df = df.fillna('NotAvailable')\n",
    "    return df\n",
    "df = giveMeWrangledData(df_concat)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2919 entries, 0 to 1458\n",
      "Data columns (total 76 columns):\n",
      "MSSubClass       2919 non-null object\n",
      "MSZoning         2919 non-null object\n",
      "LotFrontage      2919 non-null float64\n",
      "LotArea          2919 non-null float64\n",
      "Street           2919 non-null object\n",
      "Alley            2919 non-null object\n",
      "LotShape         2919 non-null object\n",
      "LandContour      2919 non-null object\n",
      "Utilities        2919 non-null object\n",
      "LotConfig        2919 non-null object\n",
      "LandSlope        2919 non-null object\n",
      "Neighborhood     2919 non-null object\n",
      "Condition1       2919 non-null object\n",
      "Condition2       2919 non-null object\n",
      "BldgType         2919 non-null object\n",
      "HouseStyle       2919 non-null object\n",
      "OverallQual      2919 non-null object\n",
      "OverallCond      2919 non-null object\n",
      "YearBuilt        2919 non-null float64\n",
      "YearRemodAdd     2919 non-null float64\n",
      "RoofStyle        2919 non-null object\n",
      "RoofMatl         2919 non-null object\n",
      "Exterior1st      2919 non-null object\n",
      "Exterior2nd      2919 non-null object\n",
      "MasVnrType       2919 non-null object\n",
      "MasVnrArea       2919 non-null float64\n",
      "ExterQual        2919 non-null object\n",
      "ExterCond        2919 non-null object\n",
      "Foundation       2919 non-null object\n",
      "BsmtQual         2919 non-null object\n",
      "BsmtCond         2919 non-null object\n",
      "BsmtExposure     2919 non-null object\n",
      "BsmtFinType1     2919 non-null object\n",
      "BsmtFinType2     2919 non-null object\n",
      "TotalBsmtSF      2919 non-null float64\n",
      "Heating          2919 non-null object\n",
      "HeatingQC        2919 non-null object\n",
      "CentralAir       2919 non-null object\n",
      "Electrical       2919 non-null object\n",
      "1stFlrSF         2919 non-null float64\n",
      "2ndFlrSF         2919 non-null float64\n",
      "LowQualFinSF     2919 non-null float64\n",
      "GrLivArea        2919 non-null float64\n",
      "BsmtFullBath     2919 non-null float64\n",
      "BsmtHalfBath     2919 non-null float64\n",
      "FullBath         2919 non-null float64\n",
      "HalfBath         2919 non-null float64\n",
      "BedroomAbvGr     2919 non-null float64\n",
      "KitchenAbvGr     2919 non-null float64\n",
      "KitchenQual      2919 non-null object\n",
      "TotRmsAbvGrd     2919 non-null float64\n",
      "Functional       2919 non-null object\n",
      "Fireplaces       2919 non-null float64\n",
      "FireplaceQu      2919 non-null object\n",
      "GarageType       2919 non-null object\n",
      "GarageFinish     2919 non-null object\n",
      "GarageCars       2919 non-null float64\n",
      "GarageArea       2919 non-null float64\n",
      "GarageQual       2919 non-null object\n",
      "GarageCond       2919 non-null object\n",
      "PavedDrive       2919 non-null object\n",
      "WoodDeckSF       2919 non-null float64\n",
      "OpenPorchSF      2919 non-null float64\n",
      "EnclosedPorch    2919 non-null float64\n",
      "3SsnPorch        2919 non-null float64\n",
      "ScreenPorch      2919 non-null float64\n",
      "PoolArea         2919 non-null float64\n",
      "PoolQC           2919 non-null object\n",
      "Fence            2919 non-null object\n",
      "MiscFeature      2919 non-null object\n",
      "MiscVal          2919 non-null float64\n",
      "MoSold           2919 non-null object\n",
      "YrSold           2919 non-null float64\n",
      "SaleType         2919 non-null object\n",
      "SaleCondition    2919 non-null object\n",
      "SalePrice        2919 non-null float64\n",
      "dtypes: float64(29), object(47)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2919 entries, 0 to 1458\n",
      "Columns: 351 entries, LotFrontage to SaleCondition_Partial\n",
      "dtypes: float64(351)\n",
      "memory usage: 7.8 MB\n"
     ]
    }
   ],
   "source": [
    "def preProcessData(df, log=False):\n",
    "    \n",
    "    print(\"Shape of the data set before pre processing : \", df.shape )\n",
    "\n",
    "    #get dummies\n",
    "    if log:\n",
    "        print(\"Categorical columns : \", list(df.select_dtypes(exclude=np.number)))\n",
    "    df = pd.get_dummies(df, dtype=np.float64)\n",
    "    \n",
    "    print(\"\\n\\nShape of the data set after pre processing : \", df.shape )\n",
    "    \n",
    "    if log:\n",
    "        print(\"Columns in the data set are : \",list(df))\n",
    "\n",
    "    return df\n",
    "\n",
    "df_prep = preProcessData(df)\n",
    "df_prep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/130262/why-not-log-transform-all-variables-that-are-not-of-main-interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350) (1460,)\n"
     ]
    }
   ],
   "source": [
    "def newBoxCoxTranformation(df,target,testFile=False, log=False):\n",
    "    \n",
    "    #assuming that only numerical features are presented\n",
    "    print(\"Shape of the dataset initial : \", df.shape)\n",
    "    \n",
    "    if not testFile:\n",
    "        df =df[df.SalePrice >0]\n",
    "        print(\"Shape of the dataset before transformation : \", df.shape)\n",
    "        y = np.array(df[target].apply( lambda x: math.log(x)))\n",
    "        X= df.drop(target,axis = 1)\n",
    "        x_columns = list(X)\n",
    "        X = preprocessing.MinMaxScaler(feature_range=(1, 2)).fit_transform(X)\n",
    "        X = pd.DataFrame(X, columns=x_columns)\n",
    "        \n",
    "        for c in list(X):\n",
    "            if len(X[c].unique()) in  [1,2]:\n",
    "                if log:\n",
    "                    print(\"Skipping Transformation for \", c, \"because unique values are :\",X[c].unique())\n",
    "            else:\n",
    "                if log:\n",
    "                    print(\"Boxcoxing : \", c)\n",
    "                X[c] = stats.boxcox(X[c])[0]\n",
    "\n",
    "        X = X.values\n",
    "        print(\"Shape of the dataset after transformation : \", X.shape, y.shape)\n",
    "        return X,y\n",
    "    else:\n",
    "        df = df[df.SalePrice == 0.0]\n",
    "        print(\"Shape of the dataset before transformation : \", df.shape)\n",
    "        X=df.drop(target,axis = 1)\n",
    "        x_columns = list(X)\n",
    "        X = preprocessing.MinMaxScaler(feature_range=(1, 2)).fit_transform(X)\n",
    "        \n",
    "        X = pd.DataFrame(X, columns=x_columns)\n",
    "        for c in list(X):\n",
    "            if len(X[c].unique()) in  [1,2]:\n",
    "                if log:\n",
    "                    print(\"Skipping Transformation for \", c, \"because unique values are :\",X[c].unique())\n",
    "            else:\n",
    "                if log:\n",
    "                    print(\"Boxcoxing : \", c)\n",
    "                X[c] = stats.boxcox(X[c])[0]\n",
    "        \n",
    "        \n",
    "        #X = preprocessing.power_transform( X, method='box-cox')\n",
    "        X = X.values\n",
    "        print(\"Shape of the dataset after transformation : \", X.shape)\n",
    "        return X\n",
    "        \n",
    "    \n",
    "\n",
    "X = newBoxCoxTranformation(df_prep,'SalePrice',True,False)  \n",
    "X,y = newBoxCoxTranformation(df_prep,'SalePrice',False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.5, random_state=random.randint(1,500))#, stratify=df.BldgType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8738126748542017"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = XGBRegressor()\n",
    "reg.fit(X_train,y_train)\n",
    "reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010992457249941136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_log_error(y_test, reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need to have different pre-processing logic to test data. We will come back to it little later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n"
     ]
    }
   ],
   "source": [
    "def checkTheTestFile(reg):\n",
    "    df_test = pd.read_csv(test_File)\n",
    "    df_test['SalePrice'] = 0.0\n",
    "    \n",
    "    df_train =  pd.read_csv(train_File)\n",
    "    df_concat = pd.concat([df_train,df_test])\n",
    "\n",
    "    #print(df_test[df_test.TotalBsmtSF.isna()])\n",
    "    #return\n",
    "    df = giveMeWrangledData(df_concat,True)\n",
    "    \n",
    "    #print(df.info())\n",
    "    df = preProcessData(df)\n",
    "    #print(df.info())\n",
    "    X = newBoxCoxTranformation(df,'SalePrice',True)\n",
    "    #print(np.sqrt(mean_squared_log_error(y, reg.predict(X))))\n",
    "    \n",
    "    df_test['SalePrice'] = np.exp(reg.predict(X))\n",
    "    \n",
    "    \n",
    "    return df_test, X, reg.predict(X)\n",
    "df_test, X_dummy, y_dummy= checkTheTestFile(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>125787.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>141982.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>191110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>200240.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>192861.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1466</td>\n",
       "      <td>184632.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1467</td>\n",
       "      <td>169653.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1468</td>\n",
       "      <td>171752.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1469</td>\n",
       "      <td>204392.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1470</td>\n",
       "      <td>138786.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1471</td>\n",
       "      <td>205484.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1472</td>\n",
       "      <td>86388.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1473</td>\n",
       "      <td>92140.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1474</td>\n",
       "      <td>154961.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1475</td>\n",
       "      <td>122290.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1476</td>\n",
       "      <td>362191.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1477</td>\n",
       "      <td>214616.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1478</td>\n",
       "      <td>275056.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1479</td>\n",
       "      <td>319877.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1480</td>\n",
       "      <td>343471.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1481</td>\n",
       "      <td>322992.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1482</td>\n",
       "      <td>206667.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1483</td>\n",
       "      <td>171770.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1484</td>\n",
       "      <td>162605.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1485</td>\n",
       "      <td>167331.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1486</td>\n",
       "      <td>207373.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1487</td>\n",
       "      <td>339368.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1488</td>\n",
       "      <td>226889.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1489</td>\n",
       "      <td>182901.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1490</td>\n",
       "      <td>250794.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>2890</td>\n",
       "      <td>100313.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>2891</td>\n",
       "      <td>142981.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>2892</td>\n",
       "      <td>49643.136719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>2893</td>\n",
       "      <td>73296.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2894</td>\n",
       "      <td>57283.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>2895</td>\n",
       "      <td>333336.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2896</td>\n",
       "      <td>267516.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2897</td>\n",
       "      <td>204014.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2898</td>\n",
       "      <td>175143.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2899</td>\n",
       "      <td>221183.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2900</td>\n",
       "      <td>152973.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2901</td>\n",
       "      <td>198043.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>2902</td>\n",
       "      <td>205682.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2903</td>\n",
       "      <td>302037.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>2904</td>\n",
       "      <td>330352.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>2905</td>\n",
       "      <td>101215.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>2906</td>\n",
       "      <td>216917.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>2907</td>\n",
       "      <td>110507.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>2908</td>\n",
       "      <td>150518.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2909</td>\n",
       "      <td>180933.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>2910</td>\n",
       "      <td>88587.289062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>2911</td>\n",
       "      <td>81811.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>2912</td>\n",
       "      <td>160916.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>2913</td>\n",
       "      <td>83344.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>2914</td>\n",
       "      <td>78217.757812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>81571.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>83344.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>144066.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>145810.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>222352.734375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  125787.546875\n",
       "1     1462  141982.984375\n",
       "2     1463  191110.000000\n",
       "3     1464  200240.312500\n",
       "4     1465  192861.265625\n",
       "5     1466  184632.828125\n",
       "6     1467  169653.500000\n",
       "7     1468  171752.890625\n",
       "8     1469  204392.515625\n",
       "9     1470  138786.703125\n",
       "10    1471  205484.062500\n",
       "11    1472   86388.726562\n",
       "12    1473   92140.015625\n",
       "13    1474  154961.734375\n",
       "14    1475  122290.453125\n",
       "15    1476  362191.968750\n",
       "16    1477  214616.812500\n",
       "17    1478  275056.718750\n",
       "18    1479  319877.843750\n",
       "19    1480  343471.218750\n",
       "20    1481  322992.937500\n",
       "21    1482  206667.562500\n",
       "22    1483  171770.421875\n",
       "23    1484  162605.546875\n",
       "24    1485  167331.453125\n",
       "25    1486  207373.578125\n",
       "26    1487  339368.656250\n",
       "27    1488  226889.875000\n",
       "28    1489  182901.843750\n",
       "29    1490  250794.281250\n",
       "...    ...            ...\n",
       "1429  2890  100313.546875\n",
       "1430  2891  142981.968750\n",
       "1431  2892   49643.136719\n",
       "1432  2893   73296.460938\n",
       "1433  2894   57283.265625\n",
       "1434  2895  333336.093750\n",
       "1435  2896  267516.062500\n",
       "1436  2897  204014.515625\n",
       "1437  2898  175143.078125\n",
       "1438  2899  221183.171875\n",
       "1439  2900  152973.171875\n",
       "1440  2901  198043.953125\n",
       "1441  2902  205682.484375\n",
       "1442  2903  302037.406250\n",
       "1443  2904  330352.750000\n",
       "1444  2905  101215.507812\n",
       "1445  2906  216917.937500\n",
       "1446  2907  110507.617188\n",
       "1447  2908  150518.984375\n",
       "1448  2909  180933.796875\n",
       "1449  2910   88587.289062\n",
       "1450  2911   81811.406250\n",
       "1451  2912  160916.640625\n",
       "1452  2913   83344.273438\n",
       "1453  2914   78217.757812\n",
       "1454  2915   81571.609375\n",
       "1455  2916   83344.273438\n",
       "1456  2917  144066.984375\n",
       "1457  2918  145810.796875\n",
       "1458  2919  222352.734375\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['Id','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['Id','SalePrice']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I got Kaggle Rank of 2539/4463 with RMSLE =0.14357\n",
    "##### As on 1/17/2019 : 9:06PM IST\n",
    "* 0.13501 ==> 2040 \n",
    "* 0.13252 ==> 1865\n",
    "* 0.13002 ==> 1704\n",
    "* 0.12658 ==> 1500\n",
    "* 0.12351 ==> 1250\n",
    "* 0.12081 ==> 1000\n",
    "* 0.11572 ==> 500\n",
    "* 0.11475 ==> 250\n",
    "* 0.11310 ==> 100\n",
    "* 0.10985 ==> 50\n",
    "* 0.10973 ==> 25\n",
    "* 0.10845 ==> 10\n",
    "* 0.08021 ==> 5\n",
    "* 0.00000 ==> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that I know around what score gets what rank; can we have a function which would what would be testing score ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logic is to predict first the testing samples. Later use that for training and predict the initial training data set. We would then have actual and predicted SalePrices with which we can calculated the RMSLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Would this logic work ? let us try for our case now and compare that with Kaggle result....Finger crossed :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forCrossValidationStratifiedShuffleSplit(df):\n",
    "    sss = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    print(\"Number of Splits configured :\", sss.get_n_splits(df, df.BldgType))\n",
    "    \n",
    "    for train_index, test_index in sss.split(df, df.BldgType):\n",
    "        yield train_index, test_index\n",
    "        \n",
    "    for train_index, test_index in sss.split(df, df.OverallQual):\n",
    "        yield train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350) (1460,)\n",
      "Number of Splits configured : 3\n"
     ]
    }
   ],
   "source": [
    "def doGridSearch():\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    df_train = pd.read_csv(train_File)\n",
    "    df_test = pd.read_csv(test_File)\n",
    "    df_test['SalePrice'] = 0\n",
    "    df_concat = pd.concat([df_train,df_test])\n",
    "    \n",
    "    df = giveMeWrangledData(df_concat)\n",
    "    df_prep = preProcessData(df)\n",
    "    \n",
    "    X,y = newBoxCoxTranformation(df_prep,'SalePrice',False,False)\n",
    "    \n",
    "    score_list = []\n",
    "    for i in range(max_depth_min,max_depth_max):\n",
    "        #for j in range(n_estimator_min,n_estimator_max,100):\n",
    "        for bytree in [0.25, 0.5, 0.75,1]:\n",
    "            for bylevel in [0.25, 0.5, 0.75,1]:\n",
    "                for lrate in [.01, .025, 0.05, .075, .1, .25, .5]:\n",
    "                    j=100\n",
    "                    loop_start = datetime.datetime.now()\n",
    "\n",
    "                    #reg = XGBRegressor(max_depth=i, n_estimators=j)\n",
    "                    reg=XGBRegressor(max_depth=i, \n",
    "                         n_estimator=j,\n",
    "                         colsample_bylevel=bylevel,\n",
    "                         colsample_bytree=bytree,\n",
    "                         learning_rate=lrate,\n",
    "                         n_jobs=n_jobs\n",
    "                        )\n",
    "\n",
    "                    #cv = ShuffleSplit(n_splits=20, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "                    #cv = ShuffleSplit(n_splits=20, test_size=.5, random_state=1986)\n",
    "                    #print(datetime.datetime())\n",
    "                    cross_cv = cross_val_score(reg, X, y,\\\n",
    "                                               cv=forCrossValidationStratifiedShuffleSplit(df_train), \\\n",
    "                                               #cv=cv, \\\n",
    "                                               scoring='neg_mean_squared_log_error',n_jobs=n_jobs)\n",
    "                    print(\" Validat Median Score : \", np.sqrt(np.median(cross_cv) * -1), \\\n",
    "                          \"Average Score : \", np.sqrt(np.average(cross_cv) * -1) )\n",
    "\n",
    "                    reg.fit(X,y)\n",
    "                    training_score = np.sqrt(mean_squared_log_error((y), (reg.predict(X))))\n",
    "                    print(\"Training Score :\", training_score)\n",
    "\n",
    "                    df_test_new, X_test, y_test = checkTheTestFile(reg)\n",
    "\n",
    "                    reg.fit(X_test,y_test)\n",
    "                    testing_score = np.sqrt(mean_squared_log_error((y), (reg.predict(X))))\n",
    "                    print(\"Testing Score :\", testing_score)\n",
    "                    print(\"Scores : \",(training_score, np.sqrt(np.average(cross_cv) * -1), testing_score,i,j,bytree, bylevel, lrate))\n",
    "                    score_list.append((training_score, np.sqrt(np.average(cross_cv) * -1), testing_score,i,j,bytree, bylevel, lrate))\n",
    "\n",
    "                    print(\"Time for max_depth -\",i,\"n_estimator -\",j,\" is : \", datetime.datetime.now() - loop_start)\n",
    "    \n",
    "    print(\"Total time for GridSearch : \", datetime.datetime.now() - start_time)\n",
    "    return score_list\n",
    "\n",
    "score_list = doGridSearch()\n",
    "#sorted(score_list,key= lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.097040</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.170715</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081912</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.155165</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067734</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>0.164185</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057025</td>\n",
       "      <td>0.010357</td>\n",
       "      <td>0.163656</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044133</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.169926</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.037271</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.170266</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030549</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>0.168559</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.023142</td>\n",
       "      <td>0.010486</td>\n",
       "      <td>0.170051</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.018912</td>\n",
       "      <td>0.010505</td>\n",
       "      <td>0.177387</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.010592</td>\n",
       "      <td>0.170507</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.010527</td>\n",
       "      <td>0.156438</td>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008761</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.168226</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    training_score  validation_score  testing_score  max_depth  n_estimator\n",
       "0         0.097040          0.010668       0.170715          3          100\n",
       "1         0.081912          0.010361       0.155165          4          100\n",
       "2         0.067734          0.010342       0.164185          5          100\n",
       "3         0.057025          0.010357       0.163656          6          100\n",
       "4         0.044133          0.010546       0.169926          7          100\n",
       "5         0.037271          0.010374       0.170266          8          100\n",
       "6         0.030549          0.010476       0.168559          9          100\n",
       "7         0.023142          0.010486       0.170051         10          100\n",
       "8         0.018912          0.010505       0.177387         11          100\n",
       "9         0.014640          0.010592       0.170507         12          100\n",
       "10        0.012290          0.010527       0.156438         13          100\n",
       "11        0.008761          0.010597       0.168226         14          100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.DataFrame(score_list,columns=[\"training_score\",\n",
    "                                           \"validation_score\",\n",
    "                                           \"testing_score\", \n",
    "                                           \"max_depth\",\n",
    "                                           \"n_estimator\"\n",
    "                                          ])\n",
    "\n",
    "temp_df.to_csv(\"GridSearchResults-\"+str(datetime.datetime.now().date()))\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.081912</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.155165</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_score  validation_score  testing_score  max_depth  n_estimator\n",
       "1        0.081912          0.010361       0.155165          4          100"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[temp_df.testing_score == temp_df.testing_score.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067734</td>\n",
       "      <td>0.010342</td>\n",
       "      <td>0.164185</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_score  validation_score  testing_score  max_depth  n_estimator\n",
       "2        0.067734          0.010342       0.164185          5          100"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[temp_df.validation_score == temp_df.validation_score.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAELCAYAAADHksFtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt0FeW9//H3x3D3ghjQBlDDUhRBBW1Ee+oNrQrWI2CpxuoqXnpoqXdrf+DytFZbzxG1esoS9YdLiqf1J1Dqha56K0KltojsIAKBIlSpRKhGRBQUBfz+/tgDbsLOZJMEY8LntdZemXnmmWfPw+j+7JnZM48iAjMzs9rs0dQbYGZmX24OCjMzS+WgMDOzVA4KMzNL5aAwM7NUDgozM0vloDAzs1QOCjMzS+WgMDOzVK2aegMaQ+fOnaO0tLSpN8PMrFmpqKh4NyK61FWvRQRFaWkpmUymqTfDzKxZkfTPQur51JOZmaVyUJiZWSoHhZmZpXJQmJlZKgeFmZmlclCYmVkqB4WZmaVqEfdR1NvTo+FfC5t6K8zM6u8rR8Gg23fpW/iIwszMUu3eRxS7OIXNzFoCH1GYmVkqB4WZmaVyUJiZWSoHhZmZpXJQmJlZqoKCQtJASUslLZc0Os/ytpImJ8vnSCpNyoslzZS0XtK9Ndb5qqSFyTpjJSkp/5mktyTNT15nN7ybZmZWX3UGhaQiYBwwCOgNXCipd41qlwNrI+JQ4B5gTFK+EfgJcEOepu8HRgA9k9fAnGX3RES/5PXUTvTHzMwaWSFHFP2B5RHxekR8CkwCBteoMxh4OJmeCpwuSRGxISJeJBsY20gqAfaJiNkREcD/AkMa0hEzM9s1CgmKbsDKnPmqpCxvnYjYDKwDiutosyqlzSslLZA0QVKnArbRzMx2kUKCQnnKoh51Cq1/P3AI0A9YDfwybwPSCEkZSZnq6uqUtzIzs4YoJCiqgANz5rsDq2qrI6kV0BF4r442u+drMyLejogtEfEZ8CDZU187iIjxEVEWEWVdunQpoBtmZlYfhQTFXKCnpB6S2gDlwLQadaYBw5PpYcCM5NpDXhGxGvhQ0gnJr52+CzwJ265fbDUUWFRQT8zMbJeo86GAEbFZ0pXAs0ARMCEiKiXdCmQiYhrwEPAbScvJHkmUb11f0gpgH6CNpCHAmRGxGBgJTATaA08nL4A7JPUjeypqBfD9RuinmZnVk1K++DcbZWVlkclkmnozzMyaFUkVEVFWVz3fmW1mZqkcFGZmlspBYWZmqRwUZmaWykFhZmapHBRmZpbKQWFmZqkcFGZmlspBYWZmqRwUZmaWykFhZmapHBRmZpbKQWFmZqkcFGZmlspBYWZmqRwUZmaWykFhZmapHBRmZpbKQWFmZqkcFGZmlspBYWZmqRwUZmaWykFhZmapCgoKSQMlLZW0XNLoPMvbSpqcLJ8jqTQpL5Y0U9J6SffWWOerkhYm64yVpKR8P0l/krQs+dup4d00M7P6qjMoJBUB44BBQG/gQkm9a1S7HFgbEYcC9wBjkvKNwE+AG/I0fT8wAuiZvAYm5aOB5yOiJ/B8Mm9mZk2kkCOK/sDyiHg9Ij4FJgGDa9QZDDycTE8FTpekiNgQES+SDYxtJJUA+0TE7IgI4H+BIXnaejin3MzMmkAhQdENWJkzX5WU5a0TEZuBdUBxHW1W1dLmARGxOmlrNbB/vgYkjZCUkZSprq4uoBtmZlYfhQSF8pRFPeo0pP6OlSPGR0RZRJR16dJlZ1Y1M7OdUEhQVAEH5sx3B1bVVkdSK6Aj8F4dbXavpc23k1NTW09RvVPANpqZ2S5SSFDMBXpK6iGpDVAOTKtRZxowPJkeBsxIrj3klZxS+lDSCcmvnb4LPJmnreE55WZm1gRa1VUhIjZLuhJ4FigCJkREpaRbgUxETAMeAn4jaTnZI4nyretLWgHsA7SRNAQ4MyIWAyOBiUB74OnkBXA7MEXS5cCbwLcbo6NmZlY/Svni32yUlZVFJpNp6s0wM2tWJFVERFld9XxntpmZpXJQmJlZKgeFmZmlclCYmVkqB4WZmaVyUJiZWSoHhZmZpXJQmJlZKgeFmZmlclCYmVkqB4WZmaVyUJiZWSoHhZmZpXJQmJlZKgeFmZmlclCYmVkqB4WZmaVyUJiZWSoHhZmZpXJQmJlZKgeFmZmlclCYmVmqgoJC0kBJSyUtlzQ6z/K2kiYny+dIKs1ZdmNSvlTSWTnl10haJKlS0rU55T+T9Jak+cnr7IZ10czMGqLOoJBUBIwDBgG9gQsl9a5R7XJgbUQcCtwDjEnW7Q2UA32AgcB9kookHQn8B9Af6AucI6lnTnv3RES/5PVUg3poZmYNUsgRRX9geUS8HhGfApOAwTXqDAYeTqanAqdLUlI+KSI+iYg3gOVJe0cAL0XERxGxGXgBGNrw7piZWWMrJCi6AStz5quSsrx1kg/+dUBxyrqLgJMlFUvqAJwNHJhT70pJCyRNkNRpJ/pjZmaNrJCgUJ6yKLBO3vKIWEL29NSfgGeAV4HNyfL7gUOAfsBq4Jd5N0oaISkjKVNdXV1nJ8zMrH4KCYoqtv+23x1YVVsdSa2AjsB7aetGxEMRcWxEnJzUXZaUvx0RWyLiM+BBsqeqdhAR4yOiLCLKunTpUkA3zMysPgoJirlAT0k9JLUhe3F6Wo0604DhyfQwYEZERFJenvwqqgfQE3gZQNL+yd+DgPOAR5P5kpx2h5I9TWVmZk2kVV0VImKzpCuBZ4EiYEJEVEq6FchExDTgIeA3kpaTPTooT9atlDQFWEz21NIVEbElafr3koqBTUn52qT8Dkn9yJ66WgF8v5H6amZm9aDsF//mraysLDKZTFNvhplZsyKpIiLK6qrnO7PNzCyVg8LMzFI5KMzMLFWdF7PNbPeyadMmqqqq2LhxY1NvijWSdu3a0b17d1q3bl2v9R0UZradqqoq9t57b0pLS8k+iceas4hgzZo1VFVV0aNHj3q14VNPZradjRs3Ulxc7JBoISRRXFzcoCNEB4WZ7cAh0bI0dH86KMzMLJWDwsy+dN5//33uu+++nV7v7LPP5v3330+t89Of/pTp06fXd9N2Sw4KM/vSqS0otmzZkqf255566in23Xff1Dq33nor3/jGNxq0fbvS5s2b6670BfOvnsysVrf8oZLFqz5o1DZ7d92Hm/+9T2qd0aNH849//IN+/frRunVr9tprL0pKSpg/fz6LFy9myJAhrFy5ko0bN3LNNdcwYsQIAEpLS8lkMqxfv55BgwZx4okn8re//Y1u3brx5JNP0r59ey655BLOOecchg0bRmlpKcOHD+cPf/gDmzZt4ne/+x29evWiurqa73znO6xZs4bjjjuOZ555hoqKCjp37rzDtm7YsIHzzz+fqqoqtmzZwk9+8hMuuOAC5s6dyzXXXMOGDRto27Ytzz//PK1bt2bkyJFkMhlatWrF3XffzYABA5g4cSJ//OMf2bhxIxs2bGDGjBnceeedTJkyhU8++YShQ4dyyy23NOp+2Bk+ojCzL53bb7+dQw45hPnz53PnnXfy8ssvc9ttt7F48WIAJkyYQEVFBZlMhrFjx7JmzZod2li2bBlXXHEFlZWV7Lvvvvz+97/P+16dO3dm3rx5jBw5krvuuguAW265hdNOO4158+YxdOhQ3nzzzVq39ZlnnqFr1668+uqrLFq0iIEDB/Lpp59ywQUX8Ktf/YpXX32V6dOn0759e8aNGwfAwoULefTRRxk+fPi2XyPNnj2bhx9+mBkzZvDcc8+xbNkyXn75ZebPn09FRQWzZs1q0L9pQ/iIwsxqVdc3/y9K//79t7sHYOzYsTz++OMArFy5kmXLllFcXLzdOj169KBfv34AfPWrX2XFihV52z7vvPO21XnssccAePHFF7e1P3DgQDp1qn2gzaOOOoobbriBUaNGcc4553DSSSexcOFCSkpKOO644wDYZ599trV71VVXAdCrVy8OPvhgXnvtNQDOOOMM9ttvPwCee+45nnvuOY455hgA1q9fz7Jlyzj55JML+edqdA4KM/vS23PPPbdN//nPf2b69OnMnj2bDh06cOqpp+a9R6Bt27bbpouKivj444/ztr21XlFR0bbrAzvzVO3DDjuMiooKnnrqKW688UbOPPNMhgwZkvcnqWnt5vYxIrjxxhv5/ve/HKMs+NSTmX3p7L333nz44Yd5l61bt45OnTrRoUMH/v73v/PSSy81+vufeOKJTJkyBch+u1+7dm2tdVetWkWHDh24+OKLueGGG5g3bx69evVi1apVzJ07F4APP/yQzZs3c/LJJ/PII48A8Nprr/Hmm29y+OGH79DmWWedxYQJE1i/fj0Ab731Fu+8805jd7NgPqIwsy+d4uJivv71r3PkkUfSvn17DjjggG3LBg4cyAMPPMDRRx/N4YcfzgknnNDo73/zzTdz4YUXMnnyZE455RRKSkrYe++989ZduHAhP/7xj9ljjz1o3bo1999/P23atGHy5MlcddVVfPzxx7Rv357p06fzwx/+kB/84AccddRRtGrViokTJ2535LPVmWeeyZIlS/ja174GwF577cVvf/tb9t9//0bvayE8cJGZbWfJkiUcccQRTb0ZTeqTTz6hqKiIVq1aMXv2bEaOHMn8+fOberMaJN9+LXTgIh9RmJnV8Oabb3L++efz2Wef0aZNGx588MGm3qQm5aAwM6uhZ8+evPLKK9uVrVmzhtNPP32Hus8///wOv7hqaRwUZmYFKC4ubvann+rLv3oyM7NUDgozM0tVUFBIGihpqaTlkkbnWd5W0uRk+RxJpTnLbkzKl0o6K6f8GkmLJFVKujanfD9Jf5K0LPlb+y2RZma2y9UZFJKKgHHAIKA3cKGk3jWqXQ6sjYhDgXuAMcm6vYFyoA8wELhPUpGkI4H/APoDfYFzJPVM2hoNPB8RPYHnk3kzM2sihRxR9AeWR8TrEfEpMAkYXKPOYODhZHoqcLqy968PBiZFxCcR8QawPGnvCOCliPgoIjYDLwBD87T1MDCkfl0zs93FXnvtBWTvkh42bFjeOqeeeip13W/1P//zP3z00Ufb5gsZ32J3UEhQdANW5sxXJWV56yQf/OuA4pR1FwEnSyqW1AE4GzgwqXNARKxO2loNNM2tiGbW7HTt2pWpU6fWe/2aQVHI+BZNqa7xORpLIT+PzTfYas3buWurk7c8IpZIGgP8CVgPvArs1GgdkkYAIwAOOuignVnVzAr19Gj418LGbfMrR8Gg21OrjBo1ioMPPpgf/vCHAPzsZz9DErNmzWLt2rVs2rSJX/ziFwwevP3JjRUrVnDOOeewaNEiPv74Yy699FIWL17MEUccsd1DAUeOHMncuXP5+OOPGTZsGLfccgtjx45l1apVDBgwgM6dOzNz5sxt41t07tyZu+++mwkTJgDwve99j2uvvZYVK1bUOu5FPmPHjuWBBx6gVatW9O7dm0mTJrF+/XquuuoqMpkMkrj55pv51re+xaOPPsp//dd/ERF885vfZMyYMUD26On666/n2Wef5Ze//CXt27fn+uuvZ/369XTu3JmJEydSUlJS792TTyFHFFV8/m0foDuwqrY6kloBHYH30taNiIci4tiIODmpuyyp87akkqStEiDvk7AiYnxElEVEWZcuXQrohpk1F+Xl5UyePHnb/JQpU7j00kt5/PHHmTdvHjNnzuRHP/pR6tNY77//fjp06MCCBQu46aabqKio2LbstttuI5PJsGDBAl544QUWLFjA1VdfTdeuXZk5cyYzZ87crq2Kigp+/etfM2fOHF566SUefPDBbTfkFTruBWTH2XjllVdYsGABDzzwAAA///nP6dixIwsXLmTBggWcdtpprFq1ilGjRjFjxgzmz5/P3LlzeeKJJ4DsQElHHnkkc+bM4fjjj+eqq65i6tSpVFRUcNlll3HTTTft/D94HQo5opgL9JTUA3iL7MXp79SoMw0YDswGhgEzIiIkTQP+n6S7ga5AT+BlAEn7R8Q7kg4CzgO+VqOt25O/Tzagf2bWEHV8899VjjnmGN555x1WrVpFdXU1nTp1oqSkhOuuu45Zs2axxx578NZbb/H222/zla98JW8bs2bN4uqrrwbg6KOP5uijj962bMqUKYwfP57NmzezevVqFi9evN3yml588UWGDh267VHg5513Hn/5y18499xzCx73Yut2XHTRRQwZMoQhQ7KXX6dPn86kSZO21enUqROzZs3i1FNPZeuX4IsuuohZs2YxZMgQioqK+Na3vgXA0qVLWbRoEWeccQaQPRXV2EcTUEBQRMRmSVcCzwJFwISIqJR0K5CJiGnAQ8BvJC0ne3RQnqxbKWkKsJjsqaUrImLrSbXfSyoGNiXlW5/jezswRdLlwJvAtxurs2bWfAwbNoypU6fyr3/9i/Lych555BGqq6upqKigdevWlJaW5h2HIle+MSHeeOMN7rrrLubOnUunTp245JJL6mwn7cil0HEvAP74xz8ya9Yspk2bxs9//nMqKyuJiB22M+392rVrR1FR0bZ6ffr0Yfbs2anb31AF3UcREU9FxGERcUhE3JaU/TQJCSJiY0R8OyIOjYj+EfF6zrq3JesdHhFP55SfFBG9I6JvRDyfU74mIk6PiJ7J3/car7tm1lyUl5czadIkpk6dyrBhw1i3bh37778/rVu3ZubMmfzzn/9MXT937IdFixaxYMECAD744AP23HNPOnbsyNtvv83TT2/7WKp1HIyTTz6ZJ554go8++ogNGzbw+OOPc9JJJ+1Ufz777DNWrlzJgAEDuOOOO3j//fdZv349Z555Jvfee++2emvXruX444/nhRde4N1332XLli08+uijnHLKKTu0efjhh1NdXb0tKDZt2kRlZeVObVchfGe2mX0p9enThw8//JBu3bpRUlLCRRddRCaToaysjEceeYRevXqlrj9y5EjWr1/P0UcfzR133EH//v0B6Nu3L8cccwx9+vThsssu4+tf//q2dUaMGMGgQYMYMGDAdm0de+yxXHLJJfTv35/jjz+e733ve9uGKS3Uli1buPjiiznqqKM45phjuO6669h33335z//8T9auXcuRRx5J3759mTlzJiUlJfz3f/83AwYMoG/fvhx77LE7XLgHaNOmDVOnTmXUqFH07duXfv368be//W2ntqsQHo/CzLbj8ShapoaMR+EjCjMzS+XHjJuZNbIrrriCv/71r9uVXXPNNVx66aVNtEUN46AwM2tk48aNa+pNaFQ+9WRmO2gJ1y7tcw3dnw4KM9tOu3btWLNmjcOihYgI1qxZQ7t27erdhk89mdl2unfvTlVVFdXV1U29KdZI2rVrR/fu3eu9voPCzLbTunVrevTo0dSbYV8iPvVkZmapHBRmZpbKQWFmZqkcFGZmlspBYWZmqRwUZmaWykFhZmapHBRmZpbKQWFmZqkcFGZmlspBYWZmqRwUZmaWykFhZmapHBRmZpaqoKCQNFDSUknLJY3Os7ytpMnJ8jmSSnOW3ZiUL5V0Vk75dZIqJS2S9Kikdkn5RElvSJqfvPo1vJtmZlZfdQaFpCJgHDAI6A1cKKl3jWqXA2sj4lDgHmBMsm5voBzoAwwE7pNUJKkbcDVQFhFHAkVJva1+HBH9ktf8BvXQzMwapJAjiv7A8oh4PSI+BSYBg2vUGQw8nExPBU6XpKR8UkR8EhFvAMuT9iA7aFJ7Sa2ADsCqhnXFzMx2hUKCohuwMme+KinLWyciNgPrgOLa1o2It4C7gDeB1cC6iHgup95tkhZIukdS253oj5mZNbJCgkJ5ymqOul5bnbzlkjqRPdroAXQF9pR0cbL8RqAXcBywHzAq70ZJIyRlJGU8tq+Z2a5TSFBUAQfmzHdnx9NE2+okp5I6Au+lrPsN4I2IqI6ITcBjwL8BRMTqyPoE+DWfn6raTkSMj4iyiCjr0qVLAd0wM7P6KCQo5gI9JfWQ1IbsRedpNepMA4Yn08OAGRERSXl58quoHkBP4GWyp5xOkNQhuZZxOrAEQFJJ8lfAEGBRQzpoZmYN06quChGxWdKVwLNkf500ISIqJd0KZCJiGvAQ8BtJy8keSZQn61ZKmgIsBjYDV0TEFmCOpKnAvKT8FWB88paPSOpC9rTVfOAHjdddMzPbWcp+8W/eysrKIpPJNPVmmJk1K5IqIqKsrnq+M9vMzFI5KMzMLJWDwszMUjkozMwslYPCzMxSOSjMzCyVg8LMzFI5KMzMLJWDwszMUjkozMwslYPCzMxSOSjMzCyVg8LMzFI5KMzMLJWDwszMUjkozMwslYPCzMxSOSjMzCyVg8LMzFI5KMzMLJWDwszMUjkozMwsVUFBIWmgpKWSlksanWd5W0mTk+VzJJXmLLsxKV8q6ayc8uskVUpaJOlRSe2S8h5JG8uSNts0vJtmZlZfdQaFpCJgHDAI6A1cKKl3jWqXA2sj4lDgHmBMsm5voBzoAwwE7pNUJKkbcDVQFhFHAkVJPZJ174mInsDapG0zM2sihRxR9AeWR8TrEfEpMAkYXKPOYODhZHoqcLokJeWTIuKTiHgDWJ60B9AKaC+pFdABWJWsc1rSBkmbQ+rXNTMzawyFBEU3YGXOfFVSlrdORGwG1gHFta0bEW8BdwFvAquBdRHxXLLO+0kbtb2XmZl9gQoJCuUpiwLr5C2X1Ins0UYPoCuwp6SLC3yv7BtKIyRlJGWqq6tr3XgzM2uYQoKiCjgwZ747sKq2OsmppI7AeynrfgN4IyKqI2IT8Bjwb8C7wL5JG7W9FwARMT4iyiKirEuXLgV0w8zM6qOQoJgL9Ex+jdSG7EXnaTXqTAOGJ9PDgBkREUl5efKrqB5AT+BlsqecTpDUIbkucTqwJFlnZtIGSZtP1r97ZmbWUHUGRXK94ErgWWAJMCUiKiXdKuncpNpDQLGk5cD1wOhk3UpgCrAYeAa4IiK2RMQcshes5wELk+0Yn7Q1Crg+aas4advMzJqIsl/im7eysrLIZDJNvRlmZs2KpIqIKKurnu/MNjOzVA4KMzNL5aAwM7NUDgozM0vloDAzs1QOCjMzS+WgMDOzVA4KMzNL5aAwM7NUDgozM0vloDAzs1QOCjMzS+WgMDOzVA4KMzNL5aAwM7NUDgozM0vloDAzs1QOCjMzS+WgMDOzVA4KMzNL5aAwM7NUDgozM0vloDAzs1QFBYWkgZKWSlouaXSe5W0lTU6Wz5FUmrPsxqR8qaSzkrLDJc3PeX0g6dpk2c8kvZWz7OzG6aqZmdVHq7oqSCoCxgFnAFXAXEnTImJxTrXLgbURcaikcmAMcIGk3kA50AfoCkyXdFhELAX65bT/FvB4Tnv3RMRdDe9eulv+UMniVR/s6rcxM9tlenfdh5v/vc8ufY9Cjij6A8sj4vWI+BSYBAyuUWcw8HAyPRU4XZKS8kkR8UlEvAEsT9rLdTrwj4j4Z307YWZmu06dRxRAN2BlznwVcHxtdSJis6R1QHFS/lKNdbvVWLcceLRG2ZWSvgtkgB9FxNqaGyVpBDAC4KCDDiqgGzva1SlsZtYSFHJEoTxlUWCd1HUltQHOBX6Xs/x+4BCyp6ZWA7/Mt1ERMT4iyiKirEuXLrVvvZmZNUghQVEFHJgz3x1YVVsdSa2AjsB7Baw7CJgXEW9vLYiItyNiS0R8BjzIjqeqzMzsC1RIUMwFekrqkRwBlAPTatSZBgxPpocBMyIikvLy5FdRPYCewMs5611IjdNOkkpyZocCiwrtjJmZNb46r1Ek1xyuBJ4FioAJEVEp6VYgExHTgIeA30haTvZIojxZt1LSFGAxsBm4IiK2AEjqQPaXVN+v8ZZ3SOpH9hTVijzLzczsC6TsF//mraysLDKZTFNvhplZsyKpIiLK6qrnO7PNzCyVg8LMzFI5KMzMLFWLuEYhqRqo753dnYF3G3FzmgP3effgPu8eGtLngyOizhvRWkRQNISkTCEXc1oS93n34D7vHr6IPvvUk5mZpXJQmJlZKgcFjG/qDWgC7vPuwX3ePezyPu/21yjMzCydjyjMzCxViw8KSRMkvSNpUU7ZfpL+JGlZ8rdTUi5JY5OhWxdIOrbptrz+aunznZL+nvTrcUn75izbYbja5iZfn3OW3SApJHVO5pv9fq6tv5KuSvZjpaQ7cspb5D6W1E/SS8mwyRlJ/ZPyZr+PASQdKGmmpCXJPr0mKf9iP8MiokW/gJOBY4FFOWV3AKOT6dHAmGT6bOBpsuNonADMaertb8Q+nwm0SqbH5PS5N/Aq0BboAfwDKGrqPjRGn5PyA8k+0PKfQOeWsp9r2ccDgOlA22R+/5a+j4HngEE5+/XPLWUfJ/0oAY5NpvcGXkv25xf6GdbijygiYhbZJ9rmyh269WFgSE75/0bWS8C+NR573izk63NEPBcRm5PZl8iODQKFDVf7pVfLfga4B/g/bD/YVrPfz7X0dyRwe0R8ktR5Jylvyfs4gH2S6Y58Pt5Ns9/HABGxOiLmJdMfAkvIjhL6hX6GtfigqMUBEbEasjsC2D8pzzfsa82hW1uCy8h+64AW3GdJ5wJvRcSrNRa11D4fBpwkaY6kFyQdl5S31P4CXAvcKWklcBdwY1Le4vosqRQ4BpjDF/wZtrsGRW0KGfa1WZN0E9mxQR7ZWpSnWrPvczLeyU3AT/MtzlPW7PtMdnyZTmRPOfwYmCJJtNz+QvYo6rqIOBC4juzYONDC+ixpL+D3wLUR8UFa1TxlDe737hoUb289HEv+bj1EL2TY12ZL0nDgHOCiSE5o0nL7fAjZ8/GvSlpBtl/zJH2FltvnKuCx5LTDy8BnZJ8D1FL7C9mRNR9Lpn/H56fUWkyfJbUmGxKPRMTWvn6hn2G7a1DkDt06HHgyp/y7yS8HTgDWbT28a+4kDQRGAedGxEc5i+oarrZZioiFEbF/RJRGRCnZ/4GOjYh/0XL38xPAaQCSDgPakH1YXIvcx4lVwCnJ9GnAsmS6Rezj5IjwIWBJRNyds+iL/Qxr6qv6u/pFdkzu1cAmsh8WlwPFwPNk/6N6HtgvqStgHNlfhSwEypp6+xuxz8vJnrucn7weyKl/U9LnpSS/IGlur3x9rrF8BZ//6qnZ7+da9nEb4LdlV6bLAAAC4UlEQVRkx5mfB5zW0vcxcCJQQfZXXXOAr7aUfZz040Syp44W5Py/e/YX/RnmO7PNzCzV7nrqyczMCuSgMDOzVA4KMzNL5aAwM7NUDgozM0vloDAzs1QOCrNGkDzu+uyc+XMljW6ktq9NHkli1iR8H4VZI5B0Cdmbm67cBW2vSNp+dyfWKYqILY29LbZ78hGF7VYklSaDwDyYDATznKT2tdQ9RNIzkiok/UVSr6T825IWSXpV0ixJbYBbgQuSAXQukHSJpHuT+hMl3Z8MQPO6pFOSQXiWSJqY8373J4PvVEq6JSm7GugKzJQ0Mym7UNLCZBvG5Ky/XtKtkuYAX9s1/4K2W2rqW9T98uuLfAGlZJ+e2y+ZnwJcXEvd54GeyfTxwIxkeiHQLZneN/l7CXBvzrrb5oGJwCSyj1cYDHwAHEX2i1pFzrZsfQxDEfBn4OhkfgWfP36kK/Am0IXs02JnAEOSZQGc39T/xn61vJePKGx39EZEzE+mK8iGx3aSxzr/G/A7SfOB/0t2tDGAvwITJf0H2Q/1QvwhIoJsyLwd2YcWfgZU5rz/+ZLmAa8AfciOZFbTcWRHcauO7EBUj5Ad+Q1gC9mnjJo1qlZNvQFmTeCTnOktQL5TT3sA70dEv5oLIuIHko4HvgnMl7RDnZT3/KzG+38GtEqe6noDcFxErE1OSbXL006+8Qa22hi+LmG7gI8ozPKI7OAwb0j6NmwbtL5vMn1IRMyJiJ+SfYz3gcCHZMc0rq99gA3AOkkHAINyluW2PQc4RVJnSUXAhcALDXhfszo5KMxqdxFwuaRXyZ4iGpyU37n1YjIwi+wjrmcCvbdezN7ZN4rscK2vJO8zgezpra3GA09LmhnZsQVuTN7vVWBeRDxZsz2zxuSfx5qZWSofUZiZWSpfzLbdnqRxwNdrFP8qIn7dFNtj9mXjU09mZpbKp57MzCyVg8LMzFI5KMzMLJWDwszMUjkozMws1f8H4F103gwIAS8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAELCAYAAADHksFtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmUVOW57/HvL83sgC2gtmACV3EAB9AWzYnRIFHBeAUN0Ta6DibkkBBnl7nCzUmM5HiOqNHEFYIXjwgxXgYxxs6KUxgS4g0i1YTZEDpCpIVgi4iCgjQ+94/aYNlU7y66G1ua32etWr33u5/3rfdlaz21h9qvIgIzM7O6fKa5O2BmZp9uThRmZpbKicLMzFI5UZiZWSonCjMzS+VEYWZmqZwozMwslROFmZmlcqIwM7NUrQoJkjQQ+BlQBPx3RNxda3tb4JfAGcBG4MqIWCOpEzADOBOYFBHX59Q5A5gEtAeeAW6KiJD0I+DfgOok9H9HxDNp/evcuXN07969kKGYmVmioqLizYjoUl9cvYlCUhEwDrgAqAIWSCqPiBU5YcOBTRFxnKQyYCxwJbAN+AFwcvLKNR4YAbxENlEMBJ5Ntj0QEffV17ddunfvTiaTKTTczMwASf8oJK6QU0/9gMqIeDUiPgCmAoNrxQwGJifLM4ABkhQRWyPiRbIJI7dzJcChETEvsg+b+iUwpJAOm5nZJ6uQRNEVWJuzXpWU5Y2JiBpgM9CpnjarUtq8XtISSRMlFRfQRzMz20cKSRTKU1b7kbOFxBQaPx44FugDrAd+krcBaYSkjKRMdXV1vhAzM2sChSSKKuCYnPVuwLq6YiS1AjoCb9XTZrd8bUbEhojYGREfAg+TPfW1h4iYEBGlEVHapUu912LMzKyBCkkUC4CeknpIagOUAeW1YsqBYcnyUGB2pEx0ERHrgXclnS1JwL8CT8Pu6xe7XAYsK2gkZma2T9R711NE1Ei6Hnie7O2xEyNiuaQxQCYiyoFHgMckVZI9kijbVV/SGuBQoI2kIcCFyR1TI/no9thn+eiOp3sk9SF7KmoN8O0mGKeZmTWQWsIMd6WlpeHbY83M9o6kiogorS+uoB/ctVjPjoJ/Lm3uXpiZNdxRp8Cgu+uPawQ/wsPMzFId2EcU+zgLm5m1BD6iMDOzVE4UZmaWyonCzMxSOVGYmVkqJwozM0vlRGFmZqmcKMzMLJUThZmZpXKiMDOzVE4UZmaWyonCzMxSOVGYmVmqghKFpIGSVkqqlDQqz/a2kqYl2+dL6p6Ud5I0R9IWST+vVecMSUuTOg8mM90h6XBJv5e0Kvlb3PhhmplZQ9WbKCQVAeOAQUAv4CpJvWqFDQc2RcRxwAPA2KR8G/AD4LY8TY8HRgA9k9fApHwUMCsiegKzknUzM2smhRxR9AMqI+LViPgAmAoMrhUzGJicLM8ABkhSRGyNiBfJJozdknmxD42Iecnc2r8EhuRpa3JOuZmZNYNCEkVXYG3OelVSljcmImqAzUCnetqsqqPNIyNifdLWeuCIAvpoZmb7SCGJQnnKak+0XUhMY+L3bEAaISkjKVNdXb03Vc3MbC8UkiiqgGNy1rsB6+qKkdQK6Ai8VU+b3epoc0NyamrXKao38jUQERMiojQiSrt06VLAMMzMrCEKSRQLgJ6SekhqA5QB5bViyoFhyfJQYHZy7SGv5JTSu5LOTu52+lfg6TxtDcspNzOzZlDvnNkRUSPpeuB5oAiYGBHLJY0BMhFRDjwCPCapkuyRRNmu+pLWAIcCbSQNAS6MiBXASGAS0B54NnkB3A1MlzQceA34WlMM1MzMGkYpX/z3G6WlpZHJZJq7G2Zm+xVJFRFRWl+cf5ltZmapnCjMzCyVE4WZmaVyojAzs1ROFGZmlsqJwszMUjlRmJlZKicKMzNL5URhZmapnCjMzCyVE4WZmaVyojAzs1ROFGZmlsqJwszMUjlRmJlZKicKMzNLVVCikDRQ0kpJlZJG5dneVtK0ZPt8Sd1zto1OyldKuiin/CZJyyQtl3RzTvmPJL0uaVHyurhxQzQzs8aoN1FIKgLGAYOAXsBVknrVChsObIqI44AHgLFJ3V5kp0XtDQwEfiGpSNLJwL8B/YDTgEsk9cxp74GI6JO8nmnUCM3MrFEKOaLoB1RGxKsR8QEwFRhcK2YwMDlZngEMkKSkfGpEbI+I1UBl0t5JwEsR8V5E1AB/BC5r/HDMzKypFZIougJrc9arkrK8MckH/2agU0rdZcC5kjpJ6gBcDByTE3e9pCWSJkoq3ovxmJlZEyskUShPWRQYk7c8Il4he3rq98BzwGKgJtk+HjgW6AOsB36St1PSCEkZSZnq6up6B2FmZg1TSKKo4uPf9rsB6+qKkdQK6Ai8lVY3Ih6JiNMj4twkdlVSviEidkbEh8DDZE9V7SEiJkREaUSUdunSpYBhmJlZQxSSKBYAPSX1kNSG7MXp8lox5cCwZHkoMDsiIikvS+6K6gH0BF4GkHRE8vezwOXAlGS9JKfdy8iepjIzs2bSqr6AiKiRdD3wPFAETIyI5ZLGAJmIKAceAR6TVEn26KAsqbtc0nRgBdlTS9dFxM6k6ScldQJ2JOWbkvJ7JPUhe+pqDfDtJhqrmZk1gLJf/PdvpaWlkclkmrsbZmb7FUkVEVFaX5x/mW1mZqmcKMzMLJUThZmZpXKiMDOzVE4UZmaWyonCzMxSOVGYmVkqJwozM0vlRGFmZqmcKMzMLJUThZmZpXKiMDOzVE4UZmaWyonCzMxSOVGYmVmqghKFpIGSVkqqlDQqz/a2kqYl2+dL6p6zbXRSvlLSRTnlN0laJmm5pJtzyg+X9HtJq5K/xY0bopmZNUa9iUJSETAOGAT0Aq6S1KtW2HBgU0QcBzwAjE3q9iI7211vYCDwC0lFkk4G/o3sfNinAZdI6pm0NQqYFRE9gVnJupmZNZNCjij6AZUR8WpEfABMBQbXihkMTE6WZwADJCkpnxoR2yNiNVCZtHcS8FJEvBcRNcAfyc6PXbutycCQhg3NzMyaQiGJoiuwNme9KinLG5N88G8GOqXUXQacK6mTpA7AxcAxScyREbE+aWs9cMTeDMjMzJpWqwJilKes9kTbdcXkLY+IVySNBX4PbAEWAzUF9OWjN5RGACMAPvvZz+5NVTMz2wuFHFFU8dG3fYBuwLq6YiS1AjoCb6XVjYhHIuL0iDg3iV2VxGyQVJK0VQK8ka9TETEhIkojorRLly4FDMPMzBqikESxAOgpqYekNmQvTpfXiikHhiXLQ4HZERFJeVlyV1QPoCfwMoCkI5K/nwUuB6bkaWsY8HRDBmZmZk2j3lNPEVEj6XrgeaAImBgRyyWNATIRUQ48AjwmqZLs0UFZUne5pOnACrKnlq6LiJ1J009K6gTsSMo3JeV3A9MlDQdeA77WVIM1M7O9p+wX//1baWlpZDKZ5u6Gmdl+RVJFRJTWF+dfZpuZWSonCjMzS+VEYWZmqZwozMwslROFmZmlcqIwM7NUThRmZpbKicLMzFI5UZiZWSonCjMzS1XIY8bN7ACyY8cOqqqq2LZtW3N3xZpIu3bt6NatG61bt25QfScKM/uYqqoqDjnkELp37052okrbn0UEGzdupKqqih49ejSoDZ96MrOP2bZtG506dXKSaCEk0alTp0YdITpRmNkenCRalsbuTycKMzNL5URhZp86b7/9Nr/4xS/2ut7FF1/M22+/nRrzwx/+kJkzZza0awekghKFpIGSVkqqlDQqz/a2kqYl2+dL6p6zbXRSvlLSRTnlt0haLmmZpCmS2iXlkyStlrQoefVp/DDNbH9SV6LYuXNnnuiPPPPMMxx22GGpMWPGjOHLX/5yo/q3L9XU1DR3F/ZQ711PkoqAccAFQBWwQFJ5RKzICRsObIqI4ySVAWOBKyX1Ijstam/gaGCmpOOBo4AbgV4R8X4yXWoZMClp73sRMaNJRmhmDXbnb5ezYt07Tdpmr6MP5Y7/2Ts1ZtSoUfz973+nT58+tG7dmoMPPpiSkhIWLVrEihUrGDJkCGvXrmXbtm3cdNNNjBgxAoDu3buTyWTYsmULgwYN4pxzzuHPf/4zXbt25emnn6Z9+/Zce+21XHLJJQwdOpTu3bszbNgwfvvb37Jjxw6eeOIJTjzxRKqrq/n617/Oxo0bOfPMM3nuueeoqKigc+fOe/R169atXHHFFVRVVbFz505+8IMfcOWVV7JgwQJuuukmtm7dStu2bZk1axatW7dm5MiRZDIZWrVqxf3330///v2ZNGkSv/vd79i2bRtbt25l9uzZ3HvvvUyfPp3t27dz2WWXceeddzbpftgbhRxR9AMqI+LViPgAmAoMrhUzGJicLM8ABih79WQwMDUitkfEaqAyaQ+ySaq9pFZAB2Bd44ZiZi3F3XffzbHHHsuiRYu49957efnll7nrrrtYsSL7/XTixIlUVFSQyWR48MEH2bhx4x5trFq1iuuuu47ly5dz2GGH8eSTT+Z9r86dO7Nw4UJGjhzJfffdB8Cdd97J+eefz8KFC7nssst47bXX6uzrc889x9FHH83ixYtZtmwZAwcO5IMPPuDKK6/kZz/7GYsXL2bmzJm0b9+ecePGAbB06VKmTJnCsGHDdt+NNG/ePCZPnszs2bN54YUXWLVqFS+//DKLFi2ioqKCuXPnNurftDEK+R1FV2BtznoVcFZdMRFRI2kz0Ckpf6lW3a4RMU/SfcBrwPvACxHxQk7cXZJ+CMwCRkXE9r0Yk5k1kfq++X9S+vXr97HfADz44IM89dRTAKxdu5ZVq1bRqVOnj9Xp0aMHffpkz1yfccYZrFmzJm/bl19++e6YX//61wC8+OKLu9sfOHAgxcXFdfbtlFNO4bbbbuP222/nkksu4Ytf/CJLly6lpKSEM888E4BDDz10d7s33HADACeeeCKf+9zn+Nvf/gbABRdcwOGHHw7ACy+8wAsvvEDfvn0B2LJlC6tWreLcc88t5J+ryRVyRJHvvqooMCZvuaRiskcbPciekjpI0jXJ9tHAicCZwOHA7Xk7JY2QlJGUqa6urn8UZrbfOuigg3Yv/+EPf2DmzJnMmzePxYsX07dv37y/EWjbtu3u5aKiojrP/e+Ky42JqP0RV7fjjz+eiooKTjnlFEaPHs2YMWOIiLy3pKa1mzvGiGD06NEsWrSIRYsWUVlZyfDhwwvuU1MrJFFUAcfkrHdjz9NEu2OSU0kdgbdS6n4ZWB0R1RGxA/g18C8AEbE+srYDj/LRqaqPiYgJEVEaEaVdunQpYBhmtr845JBDePfdd/Nu27x5M8XFxXTo0IG//vWvvPTSS3njGuOcc85h+vTpQPbb/aZNm+qMXbduHR06dOCaa67htttuY+HChZx44omsW7eOBQsWAPDuu+9SU1PDueeey+OPPw7A3/72N1577TVOOOGEPdq86KKLmDhxIlu2bAHg9ddf54033mjqYRaskFNPC4CeknoAr5O96Pz1WjHlwDBgHjAUmB0RIakc+L+S7id75NATeBn4EDhbUgeyp54GABkASSURsT65xjEEWNbIMZrZfqZTp0584Qtf4OSTT6Z9+/YceeSRu7cNHDiQhx56iFNPPZUTTjiBs88+u8nf/4477uCqq65i2rRpnHfeeZSUlHDIIYfkjV26dCnf+973+MxnPkPr1q0ZP348bdq0Ydq0adxwww28//77tG/fnpkzZ/Ld736X73znO5xyyim0atWKSZMmfezIZ5cLL7yQV155hc9//vMAHHzwwfzqV7/iiCOOaPKxFkKFHGJJuhj4KVAETIyIuySNATIRUZ7c2voY0JfskURZRLya1P0+8E2gBrg5Ip5Nyu8ErkzK/wJ8KyK2S5oNdCF72moR8J2I2JLWv9LS0shkMns/ejPbwyuvvMJJJ53U3N1oVtu3b6eoqIhWrVoxb948Ro4cyaJFi5q7W42Sb79KqoiI0vrqFvRQwIh4BnimVtkPc5a3AV+ro+5dwF15yu8A7shTfn4hfTIz21dee+01rrjiCj788EPatGnDww8/3NxdalZ+eqyZWS09e/bkL3/5y8fKNm7cyIABA/aInTVr1h53XLU0ThRmZgXo1KnTfn/6qaH8rCczM0vlRGFmZqmcKMzMLJUThZmZpXKiMLP93sEHHwxkfyU9dOjQvDFf+tKXqO/3Vj/96U957733dq8XMr/FgcCJwsxajKOPPpoZMxo+Q0HtRFHI/BbNqb75OZqKb481s7o9Owr+ubRp2zzqFBh0d2rI7bffzuc+9zm++93vAvCjH/0IScydO5dNmzaxY8cO/uM//oPBgz8+48GaNWu45JJLWLZsGe+//z7f+MY3WLFiBSeddBLvv//+7riRI0eyYMEC3n//fYYOHcqdd97Jgw8+yLp16+jfvz+dO3dmzpw5u+e36Ny5M/fffz8TJ04E4Fvf+hY333wza9asqXPei3wefPBBHnroIVq1akWvXr2YOnUqW7Zs4YYbbiCTySCJO+64g69+9atMmTKF//zP/yQi+MpXvsLYsWOB7NHTrbfeyvPPP89PfvIT2rdvz6233sqWLVvo3LkzkyZNoqSkpMG7Jx8nCjP71CkrK+Pmm2/enSimT5/Oc889xy233MKhhx7Km2++ydlnn82ll16a9ymtAOPHj6dDhw4sWbKEJUuWcPrpp+/edtddd3H44Yezc+dOBgwYwJIlS7jxxhu5//77mTNnzh4TFFVUVPDoo48yf/58IoKzzjqL8847j+LiYlatWsWUKVN4+OGHueKKK3jyySe55pprancHyM6zsXr1atq2bbv7lNaPf/xjOnbsyNKl2YS8adMm1q1bx+23305FRQXFxcVceOGF/OY3v2HIkCFs3bqVk08+mTFjxrBjxw7OO+88nn76abp06cK0adP4/ve/vzuhNRUnCjOrWz3f/PeVvn378sYbb7Bu3Tqqq6spLi6mpKSEW265hblz5/KZz3yG119/nQ0bNnDUUUflbWPu3LnceOONAJx66qmceuqpu7dNnz6dCRMmUFNTw/r161mxYsXHttf24osvctlll+1+FPjll1/On/70Jy699NKC573Y1Y+rr76aIUOGMGTIEABmzpzJ1KlTd8cUFxczd+5cvvSlL7HrydhXX301c+fOZciQIRQVFfHVr34VgJUrV7Js2TIuuOACIHsqqqmPJsCJwsw+pYYOHcqMGTP45z//SVlZGY8//jjV1dVUVFTQunVrunfvnnceilz5jjZWr17Nfffdx4IFCyguLubaa6+tt520h6fWnvci9xRXbb/73e+YO3cu5eXl/PjHP2b58uV5565Ie7927dpRVFS0O653797Mmzcvtf+N5YvZZvapVFZWxtSpU5kxYwZDhw5l8+bNHHHEEbRu3Zo5c+bwj3/8I7V+7twPy5YtY8mSJQC88847HHTQQXTs2JENGzbw7LPP7q5T1zwY5557Lr/5zW9477332Lp1K0899RRf/OIX92o8H374IWvXrqV///7cc889vP3222zZsoULL7yQn//857vjNm3axFlnncUf//hH3nzzTXbu3MmUKVM477zz9mjzhBNOoLq6enei2LFjB8uXL9+rfhXCicLMPpV69+7Nu+++S9euXSkpKeHqq68mk8lQWlrK448/zoknnphaf+TIkWzZsoVTTz2Ve+65h379snOgnXbaafTt25fevXvzzW9+ky984Qu764wYMYJBgwbRv3//j7V1+umnc+2119KvXz/OOussvvWtb+2eprRQO3fu5JprruGUU06hb9++3HLLLRx22GH8+7//O5s2beLkk0/mtNNOY86cOZSUlPBf//Vf9O/fn9NOO43TTz99jwv3AG3atGHGjBncfvvtnHbaafTp04c///nPe9WvQhQ0H8WnneejMGs6no+iZWrMfBQ+ojAzs1QFJQpJAyWtlFQpaVSe7W0lTUu2z5fUPWfb6KR8paSLcspvkbRc0jJJU5JZ8pDUI2ljVdJmm8YP08zsk3PdddfRp0+fj70effTR5u5Wg9V715OkImAccAFQBSyQVB4RK3LChgObIuI4SWXAWOBKSb3IzrHdm+yc2TMlHQ8cBdwI9IqI9yVNT+ImJXUfiIipkh5K2h7fNMM1M9v3xo0b19xdaFKFHFH0Ayoj4tWI+ACYCtS+qjIYmJwszwAGKHu/12BgakRsj4jVQGXSHmSTVHtJrYAOwLqkzvlJGyRtDmnY0MysoVrCtUv7SGP3ZyGJoiuwNme9KinLGxMRNcBmoFNddSPideA+4DVgPbA5Il5I6rydtFHXewEgaYSkjKRMdXV1AcMws0K0a9eOjRs3Olm0EBHBxo0badeuXYPbKOQHd/l+H1/7v6C6YvKWSyome7TRA3gbeELSNcDzBbxXtjBiAjABsnc95e+6me2tbt26UVVVhb+AtRzt2rWjW7duDa5fSKKoAo7JWe8GrKsjpio5ldQReCul7peB1RFRDSDp18C/AI8Dh0lqlRxV5HsvM9uHWrduTY8ePZq7G/YpUsippwVAz+RupDZkLzqX14opB4Yly0OB2ZE9bi0HypK7onoAPYGXyZ5yOltSh+S6xADglaTOnKQNkjafbvjwzMyssepNFMk3++vJnhZ6BZgeEcsljZF0aRL2CNBJUiVwKzAqqbscmA6sAJ4DrouInRExn+wF64XA0qQfE5K2bgduTdrqlLRtZmbNxL/MNjM7QPmX2WZm1iScKMzMLJUThZmZpXKiMDOzVE4UZmaWyonCzMxSOVGYmVkqJwozM0vlRGFmZqmcKMzMLJUThZmZpXKiMDOzVE4UZmaWyonCzMxSOVGYmVmqghKFpIGSVkqqlDQqz/a2kqYl2+dL6p6zbXRSvlLSRUnZCZIW5bzekXRzsu1Hkl7P2XZx0wzVzMwaot45syUVAeOAC8jOgb1AUnlErMgJGw5siojjJJUBY4ErJfUiO3Vqb+BoYKak4yNiJdAnp/3Xgady2nsgIu5r/PDMzKyxCjmi6AdURsSrEfEBMBUYXCtmMDA5WZ4BDEjmwh4MTI2I7RGxGqhM2ss1APh7RPyjoYMwM7N9p5BE0RVYm7NelZTljUnm2N5Mdr7rQuqWAVNqlV0vaYmkiZKKC+ijmZntI4UkCuUpqz3Rdl0xqXUltQEuBZ7I2T4eOJbsqan1wE/ydkoaISkjKVNdXV13783MrFEKSRRVwDE5692AdXXFSGoFdATeKqDuIGBhRGzYVRARGyJiZ0R8CDzMnqeqdsVNiIjSiCjt0qVLAcMwM7OGKCRRLAB6SuqRHAGUAeW1YsqBYcnyUGB2RERSXpbcFdUD6Am8nFPvKmqddpJUkrN6GbCs0MGYmVnTq/eup4iokXQ98DxQBEyMiOWSxgCZiCgHHgEek1RJ9kiiLKm7XNJ0YAVQA1wXETsBJHUgeyfVt2u95T2S+pA9RbUmz3YzM/sEKfvFf/9WWloamUymubthZrZfkVQREaX1xfmX2WZmlsqJwszMUjlRmJlZKicKMzNL5URhZmapnCjMzCyVE4WZmaVyojAzs1ROFGZmlsqJwszMUjlRmJlZKicKMzNL5URhZmapnCjMzCyVE4WZmaVyojAzs1QFJQpJAyWtlFQpaVSe7W0lTUu2z5fUPWfb6KR8paSLkrITJC3Keb0j6eZk2+GSfi9pVfK3uGmGamZmDVFvopBUBIwDBgG9gKsk9aoVNhzYFBHHAQ8AY5O6vchOi9obGAj8QlJRRKyMiD4R0Qc4A3gPeCppaxQwKyJ6ArOSdTMzayaFHFH0Ayoj4tWI+ACYCgyuFTMYmJwszwAGSFJSPjUitkfEaqAyaS/XAODvEfGPPG1NBobszYDMzKxpFZIougJrc9arkrK8MRFRA2wGOhVYtwyYkrN+ZESsT9paDxyRr1OSRkjKSMpUV1cXMAwzM2uIQhKF8pRFgTGpdSW1AS4FniigHx9vJGJCRJRGRGmXLl32trqZmRWokERRBRyTs94NWFdXjKRWQEfgrQLqDgIWRsSGnLINkkqStkqANwroo5mZ7SOFJIoFQE9JPZIjgDKgvFZMOTAsWR4KzI6ISMrLkruiegA9gZdz6l3Fx0871W5rGPB0oYMxM7Om16q+gIiokXQ98DxQBEyMiOWSxgCZiCgHHgEek1RJ9kiiLKm7XNJ0YAVQA1wXETsBJHUALgC+Xest7wamSxoOvAZ8rQnGaWZmDaTsF//9W2lpaWQymebuhpnZfkVSRUSU1hfnX2abmVkqJwozM0vlRGFmZqmcKMzMLJUThZmZpXKiMDOzVE4UZmaWyonCzMxSOVGYmVkqJwozM0vlRGFmZqmcKMzMLJUThZmZpXKiMDOzVE4UZmaWqqBEIWmgpJWSKiWNyrO9raRpyfb5krrnbBudlK+UdFFO+WGSZkj6q6RXJH0+Kf+RpNclLUpeFzd+mGZm1lD1znAnqQgYR3Y2uipggaTyiFiREzYc2BQRx0kqA8YCV0rqRXa2u97A0cBMSccns9z9DHguIoYmU6x2yGnvgYi4rykGaGZmjVPIEUU/oDIiXo2ID4CpwOBaMYOBycnyDGCAJCXlUyNie0SsBiqBfpIOBc4lO4UqEfFBRLzd+OGYmVlTKyRRdAXW5qxXJWV5YyKiBtgMdEqp+z+AauBRSX+R9N+SDsqJu17SEkkTJRXvzYDMzKxpFZIolKes9kTbdcXUVd4KOB0YHxF9ga3Armsf44FjgT7AeuAneTsljZCUkZSprq6udxBmZtYwhSSKKuCYnPVuwLq6YiS1AjoCb6XUrQKqImJ+Uj6DbOIgIjZExM6I+BB4mOyprz1ExISIKI2I0i5duhQwDDMza4hCEsUCoKekHslF5zKgvFZMOTAsWR4KzI6ISMrLkruiegA9gZcj4p/AWkknJHUGACsAJJXktHsZsKwB4zIzsyZS711PEVEj6XrgeaAImBgRyyWNATIRUU72ovRjkirJHkmUJXWXS5pONgnUANcldzwB3AA8niSfV4FvJOX3SOpD9hTVGuDbTTNUMzNrCGW/+O/fSktLI5PJNHc3zMz2K5IqIqK0vjj/MtvMzFI5UZiZWap6r1G0ZHf+djkr1r3T3N0wM2uwXkcfyh3/s/c+fQ8fUZiZWaoD+ohwtMeJAAAGvklEQVRiX2dhM7OWwEcUZmaWyonCzMxSOVGYmVkqJwozM0vlRGFmZqmcKMzMLJUThZmZpXKiMDOzVC3i6bGSqoF/NLB6Z+DNJuzO/sBjPjB4zAeGxoz5cxFR78xvLSJRNIakTCGP2W1JPOYDg8d8YPgkxuxTT2ZmlsqJwszMUjlRwITm7kAz8JgPDB7zgWGfj/mAv0ZhZmbpfERhZmapWnyikDRR0huSluWUHS7p95JWJX+Lk3JJelBSpaQlkk5vvp43XB1jvlfSX5NxPSXpsJxto5Mxr5R0UfP0unHyjTln222SQlLnZH2/3891jVfSDcl+XC7pnpzyFrmPJfWR9JKkRZIykvol5fv9PgaQdIykOZJeSfbpTUn5J/sZFhEt+gWcC5wOLMspuwcYlSyPAsYmyxcDzwICzgbmN3f/m3DMFwKtkuWxOWPuBSwG2gI9gL8DRc09hqYYc1J+DPA82d/ZdG4p+7mOfdwfmAm0TdaPaOn7GHgBGJSzX//QUvZxMo4S4PRk+RDgb8n+/EQ/w1r8EUVEzAXeqlU8GJicLE8GhuSU/zKyXgIOk1TyyfS06eQbc0S8EBE1yepLQLdkeTAwNSK2R8RqoBLo94l1tonUsZ8BHgD+F5B7MW6/3891jHckcHdEbE9i3kjKW/I+DuDQZLkjsC5Z3u/3MUBErI+Ihcnyu8ArQFc+4c+wFp8o6nBkRKyH7I4AjkjKuwJrc+KqkrKW5ptkv3VACx6zpEuB1yNica1NLXXMxwNflDRf0h8lnZmUt9TxAtwM3CtpLXAfMDopb3FjltQd6AvM5xP+DDtQE0VdlKesRd0WJun7QA3w+K6iPGH7/ZgldQC+D/ww3+Y8Zfv9mIFWQDHZUw7fA6ZLEi13vJA9irolIo4BbgEeScpb1JglHQw8CdwcEe+kheYpa/S4D9REsWHX4Vjyd9chehXZc9q7dOOjQ9n9nqRhwCXA1ZGc0KTljvlYsufjF0taQ3ZcCyUdRcsdcxXw6+S0w8vAh2SfA9RSxwswDPh1svwEH51SazFjltSabJJ4PCJ2jfUT/Qw7UBNFOdn/wEj+Pp1T/q/JnQNnA5t3Hd7t7yQNBG4HLo2I93I2lQNlktpK6gH0BF5ujj42pYhYGhFHRET3iOhO9n+g0yPin7Tc/fwb4HwASccDbcg+LK5F7uPEOuC8ZPl8YFWy3CL2cXJE+AjwSkTcn7Ppk/0Ma+6r+vv6BUwB1gM7yH5YDAc6AbPI/kc1Czg8iRUwjuxdIUuB0ubufxOOuZLsuctFyeuhnPjvJ2NeSXIHyf72yjfmWtvX8NFdT/v9fq5jH7cBfgUsAxYC57f0fQycA1SQvatrPnBGS9nHyTjOIXvqaEnO/7sXf9KfYf5ltpmZpTpQTz2ZmVmBnCjMzCyVE4WZmaVyojAzs1ROFGZmlsqJwszMUjlRmDWB5HHXF+esXyppVBO1fXPySBKzZuHfUZg1AUnXkv1x0/X7oO01Sdtv7kWdoojY2dR9sQOTjyjsgCKpezIJzMPJRDAvSGpfR+yxkp6TVCHpT5JOTMq/JmmZpMWS5kpqA4wBrkwm0LlS0rWSfp7ET5I0PpmA5lVJ5yWT8LwiaVLO+41PJt9ZLunOpOxG4GhgjqQ5SdlVkpYmfRibU3+LpDGS5gOf3zf/gnZAau6fqPvl1yf5ArqTfXpun2R9OnBNHbGzgJ7J8lnA7GR5KdA1WT4s+Xst8POcurvXgUnAVLKPVxgMvAOcQvaLWkVOX3Y9hqEI+ANwarK+ho8eP3I08BrQhezTYmcDQ5JtAVzR3P/GfrW8l48o7EC0OiIWJcsVZJPHxySPdf4X4AlJi4D/Q3a2MYD/B0yS9G9kP9QL8duICLJJZkNkH1r4IbA85/2vkLQQ+AvQm+xMZrWdSXYWt+rITkT1ONmZ3wB2kn3KqFmTatXcHTBrBttzlncC+U49fQZ4OyL61N4QEd+RdBbwFWCRpD1iUt7zw1rv/yHQKnmq623AmRGxKTkl1S5PO/nmG9hlW/i6hO0DPqIwyyOyk8OslvQ12D1p/WnJ8rERMT8ifkj2Md7HAO+SndO4oQ4FtgKbJR0JDMrZltv2fOA8SZ0lFQFXAX9sxPua1cuJwqxuVwPDJS0me4pocFJ+766LycBcso+4ngP02nUxe2/fKLLTtf4leZ+JZE9v7TIBeFbSnMjOLTA6eb/FwMKIeLp2e2ZNybfHmplZKh9RmJlZKl/MtgOepHHAF2oV/ywiHm2O/ph92vjUk5mZpfKpJzMzS+VEYWZmqZwozMwslROFmZmlcqIwM7NU/x+Q8s20lYHyCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = temp_df[temp_df.max_depth==3].plot.line('n_estimator','training_score',ax =ax)\n",
    "ax = temp_df[temp_df.max_depth==3].plot.line('n_estimator','validation_score',ax =ax)\n",
    "plt.show()\n",
    "fig, ax = plt.subplots()\n",
    "ax = temp_df[temp_df.max_depth==4].plot.line('n_estimator','training_score',ax =ax)\n",
    "ax = temp_df[temp_df.max_depth==4].plot.line('n_estimator','validation_score',ax =ax)\n",
    "plt.show()\n",
    "#,'validation_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kaggle score remained unchanged, this proves that our logic of test score calculation fails and there must be some value prediction which is huge which brings the average error value up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next Steps:\n",
    "* re run the grid search and note training score, validation score and testing score. This should not only double check on test score calculation but also gives us the right hyper parameter from the training and validation perspective.\n",
    "* address the runtime error during scaling or power transform. If boxcox fails attempt a log transformation at least.\n",
    "* stratify fold testing to check if the training score & validation in the previous exercise still holds goods.\n",
    "* hyper parameter research for XGBoost\n",
    "* target variable transformation\n",
    "* best of best stack approach\n",
    "* team work stack approach\n",
    "* XGBoost as the final assesser in best of best stack approach\n",
    "* XGBoost as the final assesser in the team work starck approach\n",
    "* 3 layers in stack approach: best of best candidates in the order of their accuracy feeding on input in each case.\n",
    "* re-assess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The grid search in the kaggle resulted in the different hyper parameter for lowest validation score. Not sure why is that ? validation is through the shuffle split. isnt 3 cross validation set sufficient ?\n",
    "\n",
    "##### Or it is a game of kfold shuffle split and stratify ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It only makes sense to move on for stacked approach and other hyper parameter tuning if we sort out the cross validation consistency issue. Otherwise, we cannot have the confidence of impact of changes in stacked approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The full grid search for split count = 10 is as below. It is evident that \n",
    "* testing training score is of no use. We can ignore it in the future grid searches. it would save couple minutes from one grid search.\n",
    "\n",
    "##### Following are the observation yet to be confirmed:\n",
    "* Does the testing score confidence is high; post custom stratified split ? We will have predict with the best testing score and see the rank in Kaggle. 6,800 = > 0.15404  & 3,800 ==> 0.16021\n",
    "* Does we have relation between validation score and testing score ?\n",
    "* Can we first focus on training score to be 0 with other hyper parameters ? would that be overfitting ? Should we need still learning curve of validation vs testing score.?\n",
    "* Can we ignore n_estimator and see if the validation score converges with testing score only with max_depth and other hyper parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let us talk about the hyper parameter till we get the gridsearch result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "* https://www.kaggle.com/dansbecker/xgboost\n",
    "* https://www.datacamp.com/community/tutorials/xgboost-in-python\n",
    "\n",
    "* 1 being the max value, let us have half as the value for {'colsample_bytree':0.5, 'colsample_bylevel':0.5}\n",
    "* learning_rate = 0.05 because we have already using 0.1 so far. It is suggested in the kaggle blog.\n",
    "* n_jobs= 2 /4 based on the cpu. I guess Kaggle provides 4 cpu machine. I saw the max cpu spike as 400%\n",
    "* Surprisingly and unnoticed so far that it does the cross validation by itself. so we can leverage the n_estimator to be 1000 and use early_stopping_rounds for our quick turnaround. So our 2 for loops reduced to one :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:10.9591\n",
      "Will train until validation_0-rmse hasn't improved in 250 rounds.\n",
      "[100]\tvalidation_0-rmse:0.172251\n",
      "[200]\tvalidation_0-rmse:0.145651\n",
      "[300]\tvalidation_0-rmse:0.143314\n",
      "[400]\tvalidation_0-rmse:0.142121\n",
      "[500]\tvalidation_0-rmse:0.141962\n",
      "[600]\tvalidation_0-rmse:0.142049\n",
      "[700]\tvalidation_0-rmse:0.141985\n",
      "[800]\tvalidation_0-rmse:0.142001\n",
      "[900]\tvalidation_0-rmse:0.142063\n",
      "Stopping. Best iteration:\n",
      "[738]\tvalidation_0-rmse:0.141901\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg = XGBRegressor(max_depth=4, n_estimators=1000, learning_rate = 0.05, n_jobs = 2, colsample_bylevel = 0.5, colsample_bytree = 0.5)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.5, random_state=random.randint(1,500))\n",
    "reg.fit(X_train,y_train, early_stopping_rounds=250, eval_metric='rmse',eval_set=[(X_test,y_test)], verbose=100,)\n",
    "\n",
    "'''my_model = XGBRegressor(n_estimators=1000)\n",
    "my_model.fit(train_X, train_y, early_stopping_rounds=5, \n",
    "             eval_set=[(test_X, test_y)], verbose=False)'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 15 ==> validation_0-rmse:0.145474\n",
    "* 25 ==> [ 527 ]\tvalidation_0-rmse:0.14391\n",
    "* 100 ==> [567]\tvalidation_0-rmse:0.143869\n",
    "* 250 ==> [567]\tvalidation_0-rmse:0.143869\n",
    "\n",
    "\n",
    "* for max_depth = 4\n",
    "  * [273]\tvalidation_0-rmse:0.148329\n",
    "  * [729]\tvalidation_0-rmse:0.12575\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=0.5,\n",
       "       colsample_bytree=0.5, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=1000,\n",
       "       n_jobs=2, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### n_estimator we will choose it at the end again through Stratified"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
