{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "import math\n",
    "import random\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split, cross_val_score\n",
    "from sklearn.metrics import  mean_squared_log_error\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_File = 'train.csv'\n",
    "test_File = 'test.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_File)\n",
    "df_test = pd.read_csv(test_File)\n",
    "df_test['SalePrice'] = 0\n",
    "df_concat = pd.concat([df_train,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>NotAvailable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSSubClass MSZoning  LotFrontage  LotArea Street         Alley LotShape  \\\n",
       "0         60       RL         65.0   8450.0   Pave  NotAvailable      Reg   \n",
       "1         20       RL         80.0   9600.0   Pave  NotAvailable      Reg   \n",
       "2         60       RL         68.0  11250.0   Pave  NotAvailable      IR1   \n",
       "3         70       RL         60.0   9550.0   Pave  NotAvailable      IR1   \n",
       "4         60       RL         84.0  14260.0   Pave  NotAvailable      IR1   \n",
       "\n",
       "  LandContour Utilities LotConfig    ...     PoolArea        PoolQC  \\\n",
       "0         Lvl    AllPub    Inside    ...          0.0  NotAvailable   \n",
       "1         Lvl    AllPub       FR2    ...          0.0  NotAvailable   \n",
       "2         Lvl    AllPub    Inside    ...          0.0  NotAvailable   \n",
       "3         Lvl    AllPub    Corner    ...          0.0  NotAvailable   \n",
       "4         Lvl    AllPub       FR2    ...          0.0  NotAvailable   \n",
       "\n",
       "          Fence   MiscFeature MiscVal MoSold  YrSold SaleType  SaleCondition  \\\n",
       "0  NotAvailable  NotAvailable     0.0      2  2008.0       WD         Normal   \n",
       "1  NotAvailable  NotAvailable     0.0      5  2007.0       WD         Normal   \n",
       "2  NotAvailable  NotAvailable     0.0      9  2008.0       WD         Normal   \n",
       "3  NotAvailable  NotAvailable     0.0      2  2006.0       WD        Abnorml   \n",
       "4  NotAvailable  NotAvailable     0.0     12  2008.0       WD         Normal   \n",
       "\n",
       "   SalePrice  \n",
       "0   208500.0  \n",
       "1   181500.0  \n",
       "2   223500.0  \n",
       "3   140000.0  \n",
       "4   250000.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def giveMeWrangledData(df, testFile=False, log=False):\n",
    "    \n",
    "    \n",
    "    df = df.drop(['Id', 'GarageYrBlt','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF'],axis=1)\n",
    "    \n",
    "    df['LotFrontage'] =df.LotFrontage.fillna(df.LotFrontage.mode()[0])\n",
    "    df['MasVnrArea']=df.MasVnrArea.fillna(0.0)\n",
    "    df['TotalBsmtSF'] = df.TotalBsmtSF.fillna(0)\n",
    "    df['BsmtFullBath'] = df.BsmtFullBath.fillna(0)\n",
    "    df['BsmtHalfBath'] = df.BsmtHalfBath.fillna(0)\n",
    "    df['GarageCars'] = df.GarageCars.fillna(0)\n",
    "    df['GarageArea'] = df.GarageArea.fillna(0)\n",
    "    \n",
    "    #convert data type\n",
    "    #we are being little lineant to give int64 for YearBuilt, YrSold but those guys are going to be box-coxed \n",
    "    #so let them at least enjoy the bigger size for now\n",
    "    int64_variables = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', \\\n",
    "                     'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', \\\n",
    "                     'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\\\n",
    "                     'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', \\\n",
    "                     'PoolArea', 'MiscVal', 'YrSold', 'SalePrice']\n",
    "    \n",
    "    #if testFile:\n",
    "    #    int64_variables.remove('SalePrice')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    for c in int64_variables:\n",
    "        if log:\n",
    "            print(\"Changing the data type for :\", c)\n",
    "        #df[c] = df[c].astype(np.int64)\n",
    "        df[c] = df[c].astype(np.float64)\n",
    "        \n",
    "    int_to_categorical_variables = ['MSSubClass', 'OverallQual', 'OverallCond', 'FireplaceQu', 'MoSold']\n",
    "    for c in int_to_categorical_variables:\n",
    "        df[c] = df[c].astype(str)\n",
    "        \n",
    "    df = df.fillna('NotAvailable')\n",
    "    return df\n",
    "df = giveMeWrangledData(df_concat)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2919 entries, 0 to 1458\n",
      "Data columns (total 76 columns):\n",
      "MSSubClass       2919 non-null object\n",
      "MSZoning         2919 non-null object\n",
      "LotFrontage      2919 non-null float64\n",
      "LotArea          2919 non-null float64\n",
      "Street           2919 non-null object\n",
      "Alley            2919 non-null object\n",
      "LotShape         2919 non-null object\n",
      "LandContour      2919 non-null object\n",
      "Utilities        2919 non-null object\n",
      "LotConfig        2919 non-null object\n",
      "LandSlope        2919 non-null object\n",
      "Neighborhood     2919 non-null object\n",
      "Condition1       2919 non-null object\n",
      "Condition2       2919 non-null object\n",
      "BldgType         2919 non-null object\n",
      "HouseStyle       2919 non-null object\n",
      "OverallQual      2919 non-null object\n",
      "OverallCond      2919 non-null object\n",
      "YearBuilt        2919 non-null float64\n",
      "YearRemodAdd     2919 non-null float64\n",
      "RoofStyle        2919 non-null object\n",
      "RoofMatl         2919 non-null object\n",
      "Exterior1st      2919 non-null object\n",
      "Exterior2nd      2919 non-null object\n",
      "MasVnrType       2919 non-null object\n",
      "MasVnrArea       2919 non-null float64\n",
      "ExterQual        2919 non-null object\n",
      "ExterCond        2919 non-null object\n",
      "Foundation       2919 non-null object\n",
      "BsmtQual         2919 non-null object\n",
      "BsmtCond         2919 non-null object\n",
      "BsmtExposure     2919 non-null object\n",
      "BsmtFinType1     2919 non-null object\n",
      "BsmtFinType2     2919 non-null object\n",
      "TotalBsmtSF      2919 non-null float64\n",
      "Heating          2919 non-null object\n",
      "HeatingQC        2919 non-null object\n",
      "CentralAir       2919 non-null object\n",
      "Electrical       2919 non-null object\n",
      "1stFlrSF         2919 non-null float64\n",
      "2ndFlrSF         2919 non-null float64\n",
      "LowQualFinSF     2919 non-null float64\n",
      "GrLivArea        2919 non-null float64\n",
      "BsmtFullBath     2919 non-null float64\n",
      "BsmtHalfBath     2919 non-null float64\n",
      "FullBath         2919 non-null float64\n",
      "HalfBath         2919 non-null float64\n",
      "BedroomAbvGr     2919 non-null float64\n",
      "KitchenAbvGr     2919 non-null float64\n",
      "KitchenQual      2919 non-null object\n",
      "TotRmsAbvGrd     2919 non-null float64\n",
      "Functional       2919 non-null object\n",
      "Fireplaces       2919 non-null float64\n",
      "FireplaceQu      2919 non-null object\n",
      "GarageType       2919 non-null object\n",
      "GarageFinish     2919 non-null object\n",
      "GarageCars       2919 non-null float64\n",
      "GarageArea       2919 non-null float64\n",
      "GarageQual       2919 non-null object\n",
      "GarageCond       2919 non-null object\n",
      "PavedDrive       2919 non-null object\n",
      "WoodDeckSF       2919 non-null float64\n",
      "OpenPorchSF      2919 non-null float64\n",
      "EnclosedPorch    2919 non-null float64\n",
      "3SsnPorch        2919 non-null float64\n",
      "ScreenPorch      2919 non-null float64\n",
      "PoolArea         2919 non-null float64\n",
      "PoolQC           2919 non-null object\n",
      "Fence            2919 non-null object\n",
      "MiscFeature      2919 non-null object\n",
      "MiscVal          2919 non-null float64\n",
      "MoSold           2919 non-null object\n",
      "YrSold           2919 non-null float64\n",
      "SaleType         2919 non-null object\n",
      "SaleCondition    2919 non-null object\n",
      "SalePrice        2919 non-null float64\n",
      "dtypes: float64(29), object(47)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2919 entries, 0 to 1458\n",
      "Columns: 351 entries, LotFrontage to SaleCondition_Partial\n",
      "dtypes: float64(351)\n",
      "memory usage: 7.8 MB\n"
     ]
    }
   ],
   "source": [
    "def preProcessData(df, log=False):\n",
    "    \n",
    "    print(\"Shape of the data set before pre processing : \", df.shape )\n",
    "\n",
    "    \n",
    "    #get dummies\n",
    "    if log:\n",
    "        print(\"Categorical columns : \", list(df.select_dtypes(exclude=np.number)))\n",
    "    df = pd.get_dummies(df, dtype=np.float64)\n",
    "    #df = df.drop(categorical_columns, axis=1)\n",
    "    \n",
    "    print(\"\\n\\nShape of the data set after pre processing : \", df.shape )\n",
    "    \n",
    "    if log:\n",
    "        print(\"Columns in the data set are : \",list(df))\n",
    "\n",
    "    return df\n",
    "df_prep = preProcessData(df)\n",
    "df_prep.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stats.stackexchange.com/questions/130262/why-not-log-transform-all-variables-that-are-not-of-main-interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350) (1460,)\n"
     ]
    }
   ],
   "source": [
    "def newBoxCoxTranformation(df,target,testFile=False, log=False):\n",
    "    \n",
    "    #assuming that only numerical features are presented\n",
    "    print(\"Shape of the dataset initial : \", df.shape)\n",
    "    \n",
    "    if not testFile:\n",
    "        df =df[df.SalePrice >0]\n",
    "        print(\"Shape of the dataset before transformation : \", df.shape)\n",
    "        y = np.array(df[target].apply( lambda x: math.log(x)))\n",
    "        X= df.drop(target,axis = 1)\n",
    "        x_columns = list(X)\n",
    "        X = preprocessing.MinMaxScaler(feature_range=(1, 2)).fit_transform(X)\n",
    "        X = pd.DataFrame(X, columns=x_columns)\n",
    "        \n",
    "        #print( X.MSZoning_RH.unique())\n",
    "        import time\n",
    "        \n",
    "        for c in list(X):\n",
    "            if len(X[c].unique()) in  [1,2]:\n",
    "                if log:\n",
    "                    print(\"Skipping Transformation for \", c, \"because unique values are :\",X[c].unique())\n",
    "            else:\n",
    "                if log:\n",
    "                    print(\"Boxcoxing : \", c)\n",
    "                X[c] = stats.boxcox(X[c])[0]\n",
    "\n",
    "            \n",
    "            '''if c in ['Utilities_AllPub','MSSubClass_150',]:\n",
    "               \n",
    "            elif c == 'MSZoning_RH':\n",
    "                continue\n",
    "            elif c in ['MSZoning_RL','MSZoning_RM','Street_Grvl'] :\n",
    "                print(\"Going for the x+.01\")\n",
    "                #lmax = stats.boxcox_normmax(X[c], brack=(-1.9, 2.1),  method='mle')\n",
    "                #serie_bc = stats.boxcox(X[c], lmax)\n",
    "                #print(serie_bc)\n",
    "                \n",
    "                #X[c] = X[c].apply(lambda x : math.l(x ))\n",
    "                \n",
    "                X[c] = X[c].apply(lambda x : math.tanh(x ))\n",
    "            else:\n",
    "                X[c] = stats.boxcox(X[c])[0]\n",
    "            time.sleep(.1)'''\n",
    "        \n",
    "        #X = preprocessing.power_transform( X, method='box-cox')\n",
    "        \n",
    "        \n",
    "        #print(\"X.MSZoning_RH.unique() : \",X.MSZoning_RH.unique())\n",
    "        \n",
    "        #X = pd.DataFrame(X,columns=x_columns)\n",
    "        \n",
    "        X = X.values\n",
    "        print(\"Shape of the dataset after transformation : \", X.shape, y.shape)\n",
    "        return X,y\n",
    "    else:\n",
    "        df = df[df.SalePrice == 0.0]\n",
    "        print(\"Shape of the dataset before transformation : \", df.shape)\n",
    "        X=df.drop(target,axis = 1)\n",
    "        x_columns = list(X)\n",
    "        X = preprocessing.MinMaxScaler(feature_range=(1, 2)).fit_transform(X)\n",
    "        \n",
    "        X = pd.DataFrame(X, columns=x_columns)\n",
    "        for c in list(X):\n",
    "            if len(X[c].unique()) in  [1,2]:\n",
    "                if log:\n",
    "                    print(\"Skipping Transformation for \", c, \"because unique values are :\",X[c].unique())\n",
    "            else:\n",
    "                if log:\n",
    "                    print(\"Boxcoxing : \", c)\n",
    "                X[c] = stats.boxcox(X[c])[0]\n",
    "        \n",
    "        \n",
    "        #X = preprocessing.power_transform( X, method='box-cox')\n",
    "        X = X.values\n",
    "        print(\"Shape of the dataset after transformation : \", X.shape)\n",
    "        return X\n",
    "        \n",
    "    \n",
    "\n",
    "X = newBoxCoxTranformation(df_prep,'SalePrice',True,False)  \n",
    "X,y = newBoxCoxTranformation(df_prep,'SalePrice',False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.5, random_state=random.randint(1,500))#, stratify=df.BldgType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8546477364562884"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = XGBRegressor()\n",
    "reg.fit(X_train,y_train)\n",
    "reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01114592296002113"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_log_error(y_test, reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need to have different pre-processing logic to test data. We will come back to it little later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n"
     ]
    }
   ],
   "source": [
    "def checkTheTestFile(reg):\n",
    "    df_test = pd.read_csv(test_File)\n",
    "    df_test['SalePrice'] = 0.0\n",
    "    \n",
    "    df_train =  pd.read_csv(train_File)\n",
    "    df_concat = pd.concat([df_train,df_test])\n",
    "\n",
    "    #print(df_test[df_test.TotalBsmtSF.isna()])\n",
    "    #return\n",
    "    df = giveMeWrangledData(df_concat,True)\n",
    "    \n",
    "    #print(df.info())\n",
    "    df = preProcessData(df)\n",
    "    #print(df.info())\n",
    "    X = newBoxCoxTranformation(df,'SalePrice',True)\n",
    "    #print(np.sqrt(mean_squared_log_error(y, reg.predict(X))))\n",
    "    \n",
    "    df_test['SalePrice'] = np.exp(reg.predict(X))\n",
    "    \n",
    "    \n",
    "    return df_test\n",
    "df_test = checkTheTestFile(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>125787.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>141982.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>191110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>200240.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>192861.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1466</td>\n",
       "      <td>184632.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1467</td>\n",
       "      <td>169653.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1468</td>\n",
       "      <td>171752.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1469</td>\n",
       "      <td>204392.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1470</td>\n",
       "      <td>138786.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1471</td>\n",
       "      <td>205484.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1472</td>\n",
       "      <td>86388.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1473</td>\n",
       "      <td>92140.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1474</td>\n",
       "      <td>154961.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1475</td>\n",
       "      <td>122290.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1476</td>\n",
       "      <td>362191.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1477</td>\n",
       "      <td>214616.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1478</td>\n",
       "      <td>275056.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1479</td>\n",
       "      <td>319877.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1480</td>\n",
       "      <td>343471.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1481</td>\n",
       "      <td>322992.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1482</td>\n",
       "      <td>206667.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1483</td>\n",
       "      <td>171770.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1484</td>\n",
       "      <td>162605.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1485</td>\n",
       "      <td>167331.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1486</td>\n",
       "      <td>207373.578125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1487</td>\n",
       "      <td>339368.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1488</td>\n",
       "      <td>226889.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1489</td>\n",
       "      <td>182901.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1490</td>\n",
       "      <td>250794.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>2890</td>\n",
       "      <td>100313.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>2891</td>\n",
       "      <td>142981.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>2892</td>\n",
       "      <td>49643.136719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>2893</td>\n",
       "      <td>73296.460938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>2894</td>\n",
       "      <td>57283.265625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>2895</td>\n",
       "      <td>333336.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>2896</td>\n",
       "      <td>267516.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>2897</td>\n",
       "      <td>204014.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>2898</td>\n",
       "      <td>175143.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>2899</td>\n",
       "      <td>221183.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>2900</td>\n",
       "      <td>152973.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>2901</td>\n",
       "      <td>198043.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>2902</td>\n",
       "      <td>205682.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>2903</td>\n",
       "      <td>302037.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>2904</td>\n",
       "      <td>330352.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>2905</td>\n",
       "      <td>101215.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>2906</td>\n",
       "      <td>216917.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>2907</td>\n",
       "      <td>110507.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>2908</td>\n",
       "      <td>150518.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>2909</td>\n",
       "      <td>180933.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>2910</td>\n",
       "      <td>88587.289062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>2911</td>\n",
       "      <td>81811.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>2912</td>\n",
       "      <td>160916.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>2913</td>\n",
       "      <td>83344.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>2914</td>\n",
       "      <td>78217.757812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>81571.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>83344.273438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>144066.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>145810.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>222352.734375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  125787.546875\n",
       "1     1462  141982.984375\n",
       "2     1463  191110.000000\n",
       "3     1464  200240.312500\n",
       "4     1465  192861.265625\n",
       "5     1466  184632.828125\n",
       "6     1467  169653.500000\n",
       "7     1468  171752.890625\n",
       "8     1469  204392.515625\n",
       "9     1470  138786.703125\n",
       "10    1471  205484.062500\n",
       "11    1472   86388.726562\n",
       "12    1473   92140.015625\n",
       "13    1474  154961.734375\n",
       "14    1475  122290.453125\n",
       "15    1476  362191.968750\n",
       "16    1477  214616.812500\n",
       "17    1478  275056.718750\n",
       "18    1479  319877.843750\n",
       "19    1480  343471.218750\n",
       "20    1481  322992.937500\n",
       "21    1482  206667.562500\n",
       "22    1483  171770.421875\n",
       "23    1484  162605.546875\n",
       "24    1485  167331.453125\n",
       "25    1486  207373.578125\n",
       "26    1487  339368.656250\n",
       "27    1488  226889.875000\n",
       "28    1489  182901.843750\n",
       "29    1490  250794.281250\n",
       "...    ...            ...\n",
       "1429  2890  100313.546875\n",
       "1430  2891  142981.968750\n",
       "1431  2892   49643.136719\n",
       "1432  2893   73296.460938\n",
       "1433  2894   57283.265625\n",
       "1434  2895  333336.093750\n",
       "1435  2896  267516.062500\n",
       "1436  2897  204014.515625\n",
       "1437  2898  175143.078125\n",
       "1438  2899  221183.171875\n",
       "1439  2900  152973.171875\n",
       "1440  2901  198043.953125\n",
       "1441  2902  205682.484375\n",
       "1442  2903  302037.406250\n",
       "1443  2904  330352.750000\n",
       "1444  2905  101215.507812\n",
       "1445  2906  216917.937500\n",
       "1446  2907  110507.617188\n",
       "1447  2908  150518.984375\n",
       "1448  2909  180933.796875\n",
       "1449  2910   88587.289062\n",
       "1450  2911   81811.406250\n",
       "1451  2912  160916.640625\n",
       "1452  2913   83344.273438\n",
       "1453  2914   78217.757812\n",
       "1454  2915   81571.609375\n",
       "1455  2916   83344.273438\n",
       "1456  2917  144066.984375\n",
       "1457  2918  145810.796875\n",
       "1458  2919  222352.734375\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['Id','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['Id','SalePrice']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I got Kaggle Rank of 2539/4463 with RMSLE =0.14357\n",
    "##### As on 1/17/2019 : 9:06PM IST\n",
    "* 0.13501 ==> 2040 \n",
    "* 0.13252 ==> 1865\n",
    "* 0.13002 ==> 1704\n",
    "* 0.12658 ==> 1500\n",
    "* 0.12351 ==> 1250\n",
    "* 0.12081 ==> 1000\n",
    "* 0.11572 ==> 500\n",
    "* 0.11475 ==> 250\n",
    "* 0.11310 ==> 100\n",
    "* 0.10985 ==> 50\n",
    "* 0.10973 ==> 25\n",
    "* 0.10845 ==> 10\n",
    "* 0.08021 ==> 5\n",
    "* 0.00000 ==> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that I know around what score gets what rank; can we have a function which would what would be testing score ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logic is to predict first the testing samples. Later use that for training and predict the initial training data set. We would then have actual and predicted SalePrices with which we can calculated the RMSLE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Would this logic work ? let us try for our case now and compare that with Kaggle result....Finger crossed :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.00604585540551122 Average Score :  0.005923071617358857\n",
      "Training Score : 0.002591130324273707\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 3 n_estimator : 100 RMSLE :  0.16589711298464754\n",
      "Total time for validation ot testing score :  0:00:18.156452\n",
      "0.002591130324273707 0.005923071617358857 0.16589711298464754 3 100\n"
     ]
    }
   ],
   "source": [
    "def checkTheTestingScore(df_test, max_depth, n_estimator):\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    " \n",
    "    df_train =  pd.read_csv(train_File)\n",
    "    df_train.SalePrice = 0\n",
    "    df_concat = pd.concat([df_train,df_test])\n",
    "    \n",
    "    X,y = newBoxCoxTranformation(preProcessData((giveMeWrangledData(df_concat))),'SalePrice')\n",
    "    reg=XGBRegressor(max_depth=max_depth, n_estimator=n_estimator)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=3, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "    #print(datetime.datetime())\n",
    "    cross_cv = cross_val_score(reg,X,y,cv=cv, scoring='neg_mean_squared_log_error',n_jobs=3)\n",
    "    print(\" Validat Median Score : \", np.sqrt(np.median(cross_cv) * -1), \"Average Score : \", np.sqrt(np.average(cross_cv) * -1) )\n",
    "    \n",
    "    reg.fit(X,y)\n",
    "    training_score = np.sqrt(mean_squared_log_error(y, reg.predict(X)))\n",
    "    print(\"Training Score :\", training_score)\n",
    "    \n",
    "    X = newBoxCoxTranformation(preProcessData((giveMeWrangledData(df_concat))),'SalePrice',True)\n",
    "    df_train =  pd.read_csv(train_File)\n",
    "    df_train['predicted_SalePrice']=np.exp(reg.predict(X))\n",
    "    \n",
    "    testing_score = np.sqrt(mean_squared_log_error(df_train.SalePrice,df_train.predicted_SalePrice))\n",
    "    \n",
    "    print(\"max_depth :\", max_depth, \"n_estimator :\", n_estimator,\"RMSLE : \", testing_score)\n",
    "    print(\"Total time for validation to testing score : \", datetime.datetime.now()- start_time)\n",
    "    \n",
    "    return [training_score, np.sqrt(np.average(cross_cv) * -1), testing_score]\n",
    "    \n",
    "dummy = checkTheTestingScore(df_test,3,100)\n",
    "print(dummy[0],dummy[1],dummy[2],3,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is good news; we have the RMSLE calculation matching amost to that of Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350) (1460,)\n",
      " Validat Median Score :  0.011747345176051804 Average Score :  0.011887554193449215\n",
      "Training Score : 0.007038429364622834\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.0055546671024981255 Average Score :  0.005797720480892256\n",
      "Training Score : 0.002591130324273707\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 3 n_estimator : 100 RMSLE :  0.16589711298464754\n",
      "Total time for validation ot testing score :  0:00:04.849035\n",
      "Time for max_depth - 3 n_estimator - 100  is :  0:00:24.277087\n",
      " Validat Median Score :  0.01189970198792782 Average Score :  0.011924474298531518\n",
      "Training Score : 0.005636137999428832\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.00830966012863398 Average Score :  0.008368360104090212\n",
      "Training Score : 0.002953958528744047\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 3 n_estimator : 200 RMSLE :  0.16361675537052014\n",
      "Total time for validation ot testing score :  0:00:05.060469\n",
      "Time for max_depth - 3 n_estimator - 200  is :  0:00:14.414459\n",
      " Validat Median Score :  0.012092115377602092 Average Score :  0.012258046961865424\n",
      "Training Score : 0.00472990776281659\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.008993787393432286 Average Score :  0.00913878352529652\n",
      "Training Score : 0.0032870140351473416\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 3 n_estimator : 300 RMSLE :  0.1585458164996054\n",
      "Total time for validation ot testing score :  0:00:04.928822\n",
      "Time for max_depth - 3 n_estimator - 300  is :  0:00:18.283115\n",
      " Validat Median Score :  0.013659091068948892 Average Score :  0.013545470423398506\n",
      "Training Score : 0.0041376578077405475\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.0086800044998537 Average Score :  0.009104610131325437\n",
      "Training Score : 0.0034640425922894623\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 3 n_estimator : 400 RMSLE :  0.1589103286525219\n",
      "Total time for validation ot testing score :  0:00:07.608656\n",
      "Time for max_depth - 3 n_estimator - 400  is :  0:00:23.262801\n",
      " Validat Median Score :  0.010854155966298022 Average Score :  0.011310074590648828\n",
      "Training Score : 0.0036123164851393627\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.006449945824780498 Average Score :  0.006495988157787958\n",
      "Training Score : 0.00357503097746391\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 3 n_estimator : 500 RMSLE :  0.15997913025563054\n",
      "Total time for validation ot testing score :  0:00:06.266243\n",
      "Time for max_depth - 3 n_estimator - 500  is :  0:00:30.017741\n",
      " Validat Median Score :  0.012250595600344544 Average Score :  0.012279115868924856\n",
      "Training Score : 0.003214561047426924\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.008038471458705336 Average Score :  0.0079514568641878\n",
      "Training Score : 0.0037099305597487154\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 3 n_estimator : 600 RMSLE :  0.16678947098039096\n",
      "Total time for validation ot testing score :  0:00:05.367650\n",
      "Time for max_depth - 3 n_estimator - 600  is :  0:00:33.150363\n",
      " Validat Median Score :  0.013531369225424191 Average Score :  0.013542225704918878\n",
      "Training Score : 0.0028983086065104\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.009733022954699957 Average Score :  0.009665851676116772\n",
      "Training Score : 0.0037519689958274947\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 3 n_estimator : 700 RMSLE :  0.16243589961039318\n",
      "Total time for validation ot testing score :  0:00:05.030549\n",
      "Time for max_depth - 3 n_estimator - 700  is :  0:00:29.926982\n",
      " Validat Median Score :  0.0133842177998135 Average Score :  0.01385176218426239\n",
      "Training Score : 0.0026194280781897433\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.007796707610810753 Average Score :  0.007858682241377575\n",
      "Training Score : 0.0037789470570832027\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 3 n_estimator : 800 RMSLE :  0.16636903816560966\n",
      "Total time for validation ot testing score :  0:00:05.180151\n",
      "Time for max_depth - 3 n_estimator - 800  is :  0:00:32.441259\n",
      " Validat Median Score :  0.011774569719318647 Average Score :  0.011662228326861321\n",
      "Training Score : 0.005939174838228012\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.006019841041397743 Average Score :  0.005850464644086697\n",
      "Training Score : 0.0022243868867742387\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 4 n_estimator : 100 RMSLE :  0.15527371006067386\n",
      "Total time for validation ot testing score :  0:00:05.827419\n",
      "Time for max_depth - 4 n_estimator - 100  is :  0:00:12.779828\n",
      " Validat Median Score :  0.012374706785345347 Average Score :  0.012355421819497281\n",
      "Training Score : 0.004268714450990581\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.007736957552685081 Average Score :  0.00783773833320284\n",
      "Training Score : 0.0026585927751457943\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 4 n_estimator : 200 RMSLE :  0.1467279830372148\n",
      "Total time for validation ot testing score :  0:00:05.074432\n",
      "Time for max_depth - 4 n_estimator - 200  is :  0:00:14.684737\n",
      " Validat Median Score :  0.012827280145313596 Average Score :  0.01296315382519476\n",
      "Training Score : 0.003305073964834737\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.006249579216420965 Average Score :  0.00640172186969589\n",
      "Training Score : 0.0027985183902009218\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 4 n_estimator : 300 RMSLE :  0.14960519776842063\n",
      "Total time for validation ot testing score :  0:00:05.698765\n",
      "Time for max_depth - 4 n_estimator - 300  is :  0:00:20.651781\n",
      " Validat Median Score :  0.012861400704623022 Average Score :  0.012456653589596233\n",
      "Training Score : 0.002657514871910279\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.006845635997599227 Average Score :  0.006908030027384827\n",
      "Training Score : 0.002898619095733443\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 4 n_estimator : 400 RMSLE :  0.15048094966299977\n",
      "Total time for validation ot testing score :  0:00:05.666848\n",
      "Time for max_depth - 4 n_estimator - 400  is :  0:00:25.884788\n",
      " Validat Median Score :  0.011418315780289023 Average Score :  0.01140495911477339\n",
      "Training Score : 0.002142120581252479\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.006533424537534767 Average Score :  0.006847747143728902\n",
      "Training Score : 0.0029753645681218966\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 4 n_estimator : 500 RMSLE :  0.14971132084391342\n",
      "Total time for validation ot testing score :  0:00:05.837392\n",
      "Time for max_depth - 4 n_estimator - 500  is :  0:00:31.647382\n",
      " Validat Median Score :  0.011704005215441264 Average Score :  0.01151865344425009\n",
      "Training Score : 0.001762809187097093\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.009078341055127857 Average Score :  0.008861928390362477\n",
      "Training Score : 0.0030275658780737295\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 4 n_estimator : 600 RMSLE :  0.15078729871065003\n",
      "Total time for validation ot testing score :  0:00:04.919845\n",
      "Time for max_depth - 4 n_estimator - 600  is :  0:00:36.546284\n",
      " Validat Median Score :  0.01205915885362366 Average Score :  0.012194260036303835\n",
      "Training Score : 0.0015177393392584839\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.007473478586578695 Average Score :  0.0074145559170415995\n",
      "Training Score : 0.003083339874275079\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 4 n_estimator : 700 RMSLE :  0.15263580597644802\n",
      "Total time for validation ot testing score :  0:00:05.268914\n",
      "Time for max_depth - 4 n_estimator - 700  is :  0:00:37.211492\n",
      " Validat Median Score :  0.012413527462468031 Average Score :  0.012371635152666115\n",
      "Training Score : 0.0012771681287370507\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350)\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1459, 351)\n",
      "Shape of the dataset after transformation :  (1459, 350) (1459,)\n",
      " Validat Median Score :  0.0073496086487760195 Average Score :  0.00729388764553162\n",
      "Training Score : 0.003109576673595675\n",
      "Shape of the data set before pre processing :  (2919, 76)\n",
      "\n",
      "\n",
      "Shape of the data set after pre processing :  (2919, 351)\n",
      "Shape of the dataset initial :  (2919, 351)\n",
      "Shape of the dataset before transformation :  (1460, 351)\n",
      "Shape of the dataset after transformation :  (1460, 350)\n",
      "max_depth : 4 n_estimator : 800 RMSLE :  0.1550713313523382\n",
      "Total time for validation ot testing score :  0:00:06.766905\n",
      "Time for max_depth - 4 n_estimator - 800  is :  0:00:49.995323\n",
      "Total time for GridSearch :  0:07:15.781806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0012771681287370507,\n",
       "  0.012371635152666115,\n",
       "  0.003109576673595675,\n",
       "  0.00729388764553162,\n",
       "  0.1550713313523382,\n",
       "  4,\n",
       "  800),\n",
       " (0.0015177393392584839,\n",
       "  0.012194260036303835,\n",
       "  0.003083339874275079,\n",
       "  0.0074145559170415995,\n",
       "  0.15263580597644802,\n",
       "  4,\n",
       "  700),\n",
       " (0.001762809187097093,\n",
       "  0.01151865344425009,\n",
       "  0.0030275658780737295,\n",
       "  0.008861928390362477,\n",
       "  0.15078729871065003,\n",
       "  4,\n",
       "  600),\n",
       " (0.002142120581252479,\n",
       "  0.01140495911477339,\n",
       "  0.0029753645681218966,\n",
       "  0.006847747143728902,\n",
       "  0.14971132084391342,\n",
       "  4,\n",
       "  500),\n",
       " (0.0026194280781897433,\n",
       "  0.01385176218426239,\n",
       "  0.0037789470570832027,\n",
       "  0.007858682241377575,\n",
       "  0.16636903816560966,\n",
       "  3,\n",
       "  800),\n",
       " (0.002657514871910279,\n",
       "  0.012456653589596233,\n",
       "  0.002898619095733443,\n",
       "  0.006908030027384827,\n",
       "  0.15048094966299977,\n",
       "  4,\n",
       "  400),\n",
       " (0.0028983086065104,\n",
       "  0.013542225704918878,\n",
       "  0.0037519689958274947,\n",
       "  0.009665851676116772,\n",
       "  0.16243589961039318,\n",
       "  3,\n",
       "  700),\n",
       " (0.003214561047426924,\n",
       "  0.012279115868924856,\n",
       "  0.0037099305597487154,\n",
       "  0.0079514568641878,\n",
       "  0.16678947098039096,\n",
       "  3,\n",
       "  600),\n",
       " (0.003305073964834737,\n",
       "  0.01296315382519476,\n",
       "  0.0027985183902009218,\n",
       "  0.00640172186969589,\n",
       "  0.14960519776842063,\n",
       "  4,\n",
       "  300),\n",
       " (0.0036123164851393627,\n",
       "  0.011310074590648828,\n",
       "  0.00357503097746391,\n",
       "  0.006495988157787958,\n",
       "  0.15997913025563054,\n",
       "  3,\n",
       "  500),\n",
       " (0.0041376578077405475,\n",
       "  0.013545470423398506,\n",
       "  0.0034640425922894623,\n",
       "  0.009104610131325437,\n",
       "  0.1589103286525219,\n",
       "  3,\n",
       "  400),\n",
       " (0.004268714450990581,\n",
       "  0.012355421819497281,\n",
       "  0.0026585927751457943,\n",
       "  0.00783773833320284,\n",
       "  0.1467279830372148,\n",
       "  4,\n",
       "  200),\n",
       " (0.00472990776281659,\n",
       "  0.012258046961865424,\n",
       "  0.0032870140351473416,\n",
       "  0.00913878352529652,\n",
       "  0.1585458164996054,\n",
       "  3,\n",
       "  300),\n",
       " (0.005636137999428832,\n",
       "  0.011924474298531518,\n",
       "  0.002953958528744047,\n",
       "  0.008368360104090212,\n",
       "  0.16361675537052014,\n",
       "  3,\n",
       "  200),\n",
       " (0.005939174838228012,\n",
       "  0.011662228326861321,\n",
       "  0.0022243868867742387,\n",
       "  0.005850464644086697,\n",
       "  0.15527371006067386,\n",
       "  4,\n",
       "  100),\n",
       " (0.007038429364622834,\n",
       "  0.011887554193449215,\n",
       "  0.002591130324273707,\n",
       "  0.005797720480892256,\n",
       "  0.16589711298464754,\n",
       "  3,\n",
       "  100)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def doGridSearch():\n",
    "    \n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    df_train = pd.read_csv(train_File)\n",
    "    df_test = pd.read_csv(test_File)\n",
    "    df_test['SalePrice'] = 0\n",
    "    df_concat = pd.concat([df_train,df_test])\n",
    "    \n",
    "    df = giveMeWrangledData(df_concat)\n",
    "    df_prep = preProcessData(df)\n",
    "    \n",
    "    X,y = newBoxCoxTranformation(df_prep,'SalePrice',False,False)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, \\\n",
    "                                                        random_state=random.randint(1,500))#, stratify=df.BldgType)\n",
    "    \n",
    "    \n",
    "    score_list = []\n",
    "    for i in range(3,5):\n",
    "        for j in range(100,900,100):\n",
    "            loop_start = datetime.datetime.now()\n",
    "            \n",
    "            reg = XGBRegressor(max_depth=i, n_estimators=j)\n",
    "\n",
    "            cv = ShuffleSplit(n_splits=3, test_size=random.randint(7,9)/10, random_state=random.randint(1,1000))\n",
    "            #print(datetime.datetime())\n",
    "            cross_cv = cross_val_score(reg,X,y,cv=cv, scoring='neg_mean_squared_log_error',n_jobs=3)\n",
    "            print(\" Validat Median Score : \", np.sqrt(np.median(cross_cv) * -1), \\\n",
    "                  \"Average Score : \", np.sqrt(np.average(cross_cv) * -1) )\n",
    "\n",
    "            reg.fit(X,y)\n",
    "            training_score = np.sqrt(mean_squared_log_error(y, reg.predict(X)))\n",
    "            print(\"Training Score :\", training_score)\n",
    "            \n",
    "            scores = checkTheTestingScore(checkTheTestFile(reg),i,j)\n",
    "            score_list.append((training_score, np.sqrt(np.average(cross_cv) * -1), scores[0],scores[1],scores[2],i,j))\n",
    "            \n",
    "            print(\"Time for max_depth -\",i,\"n_estimator -\",j,\" is : \", datetime.datetime.now() - loop_start)\n",
    "    \n",
    "    print(\"Total time for GridSearch : \", datetime.datetime.now() - start_time)\n",
    "    return score_list\n",
    "\n",
    "score_list = doGridSearch()\n",
    "sorted(score_list,key= lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>predict_training_score</th>\n",
       "      <th>predict_validation_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.165897</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.163617</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.009139</td>\n",
       "      <td>0.158546</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>0.158910</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.159979</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.012279</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.166789</td>\n",
       "      <td>3</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.162436</td>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.166369</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.146728</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>0.149605</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>0.149711</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.150787</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.152636</td>\n",
       "      <td>4</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>0.155071</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    training_score  validation_score  predict_training_score  \\\n",
       "0         0.007038          0.011888                0.002591   \n",
       "1         0.005636          0.011924                0.002954   \n",
       "2         0.004730          0.012258                0.003287   \n",
       "3         0.004138          0.013545                0.003464   \n",
       "4         0.003612          0.011310                0.003575   \n",
       "5         0.003215          0.012279                0.003710   \n",
       "6         0.002898          0.013542                0.003752   \n",
       "7         0.002619          0.013852                0.003779   \n",
       "8         0.005939          0.011662                0.002224   \n",
       "9         0.004269          0.012355                0.002659   \n",
       "10        0.003305          0.012963                0.002799   \n",
       "11        0.002658          0.012457                0.002899   \n",
       "12        0.002142          0.011405                0.002975   \n",
       "13        0.001763          0.011519                0.003028   \n",
       "14        0.001518          0.012194                0.003083   \n",
       "15        0.001277          0.012372                0.003110   \n",
       "\n",
       "    predict_validation_score  testing_score  max_depth  n_estimator  \n",
       "0                   0.005798       0.165897          3          100  \n",
       "1                   0.008368       0.163617          3          200  \n",
       "2                   0.009139       0.158546          3          300  \n",
       "3                   0.009105       0.158910          3          400  \n",
       "4                   0.006496       0.159979          3          500  \n",
       "5                   0.007951       0.166789          3          600  \n",
       "6                   0.009666       0.162436          3          700  \n",
       "7                   0.007859       0.166369          3          800  \n",
       "8                   0.005850       0.155274          4          100  \n",
       "9                   0.007838       0.146728          4          200  \n",
       "10                  0.006402       0.149605          4          300  \n",
       "11                  0.006908       0.150481          4          400  \n",
       "12                  0.006848       0.149711          4          500  \n",
       "13                  0.008862       0.150787          4          600  \n",
       "14                  0.007415       0.152636          4          700  \n",
       "15                  0.007294       0.155071          4          800  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = pd.DataFrame(score_list,columns=[\"training_score\",\\\n",
    "                                           \"validation_score\",\\\n",
    "                                           \"predict_training_score\",\\\n",
    "                                           \"predict_validation_score\",\\\n",
    "                                           \"testing_score\",\n",
    "                                           \"max_depth\",\n",
    "                                           \"n_estimator\"\n",
    "                                          ])\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>predict_training_score</th>\n",
       "      <th>predict_validation_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.159979</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>0.149711</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.150787</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.165897</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.163617</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.152636</td>\n",
       "      <td>4</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.009139</td>\n",
       "      <td>0.158546</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.012279</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.166789</td>\n",
       "      <td>3</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.146728</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>0.155071</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>0.149605</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.162436</td>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>0.158910</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.166369</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    training_score  validation_score  predict_training_score  \\\n",
       "4         0.003612          0.011310                0.003575   \n",
       "12        0.002142          0.011405                0.002975   \n",
       "13        0.001763          0.011519                0.003028   \n",
       "8         0.005939          0.011662                0.002224   \n",
       "0         0.007038          0.011888                0.002591   \n",
       "1         0.005636          0.011924                0.002954   \n",
       "14        0.001518          0.012194                0.003083   \n",
       "2         0.004730          0.012258                0.003287   \n",
       "5         0.003215          0.012279                0.003710   \n",
       "9         0.004269          0.012355                0.002659   \n",
       "15        0.001277          0.012372                0.003110   \n",
       "11        0.002658          0.012457                0.002899   \n",
       "10        0.003305          0.012963                0.002799   \n",
       "6         0.002898          0.013542                0.003752   \n",
       "3         0.004138          0.013545                0.003464   \n",
       "7         0.002619          0.013852                0.003779   \n",
       "\n",
       "    predict_validation_score  testing_score  max_depth  n_estimator  \n",
       "4                   0.006496       0.159979          3          500  \n",
       "12                  0.006848       0.149711          4          500  \n",
       "13                  0.008862       0.150787          4          600  \n",
       "8                   0.005850       0.155274          4          100  \n",
       "0                   0.005798       0.165897          3          100  \n",
       "1                   0.008368       0.163617          3          200  \n",
       "14                  0.007415       0.152636          4          700  \n",
       "2                   0.009139       0.158546          3          300  \n",
       "5                   0.007951       0.166789          3          600  \n",
       "9                   0.007838       0.146728          4          200  \n",
       "15                  0.007294       0.155071          4          800  \n",
       "11                  0.006908       0.150481          4          400  \n",
       "10                  0.006402       0.149605          4          300  \n",
       "6                   0.009666       0.162436          3          700  \n",
       "3                   0.009105       0.158910          3          400  \n",
       "7                   0.007859       0.166369          3          800  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.sort_values(by='validation_score',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>predict_training_score</th>\n",
       "      <th>predict_validation_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>0.007294</td>\n",
       "      <td>0.155071</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.152636</td>\n",
       "      <td>4</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.011519</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.150787</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.011405</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.006848</td>\n",
       "      <td>0.149711</td>\n",
       "      <td>4</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.166369</td>\n",
       "      <td>3</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.012457</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.006908</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>4</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.162436</td>\n",
       "      <td>3</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.012279</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.166789</td>\n",
       "      <td>3</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.006402</td>\n",
       "      <td>0.149605</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.011310</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.159979</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.009105</td>\n",
       "      <td>0.158910</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.146728</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004730</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.009139</td>\n",
       "      <td>0.158546</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005636</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.163617</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005939</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007038</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.165897</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    training_score  validation_score  predict_training_score  \\\n",
       "15        0.001277          0.012372                0.003110   \n",
       "14        0.001518          0.012194                0.003083   \n",
       "13        0.001763          0.011519                0.003028   \n",
       "12        0.002142          0.011405                0.002975   \n",
       "7         0.002619          0.013852                0.003779   \n",
       "11        0.002658          0.012457                0.002899   \n",
       "6         0.002898          0.013542                0.003752   \n",
       "5         0.003215          0.012279                0.003710   \n",
       "10        0.003305          0.012963                0.002799   \n",
       "4         0.003612          0.011310                0.003575   \n",
       "3         0.004138          0.013545                0.003464   \n",
       "9         0.004269          0.012355                0.002659   \n",
       "2         0.004730          0.012258                0.003287   \n",
       "1         0.005636          0.011924                0.002954   \n",
       "8         0.005939          0.011662                0.002224   \n",
       "0         0.007038          0.011888                0.002591   \n",
       "\n",
       "    predict_validation_score  testing_score  max_depth  n_estimator  \n",
       "15                  0.007294       0.155071          4          800  \n",
       "14                  0.007415       0.152636          4          700  \n",
       "13                  0.008862       0.150787          4          600  \n",
       "12                  0.006848       0.149711          4          500  \n",
       "7                   0.007859       0.166369          3          800  \n",
       "11                  0.006908       0.150481          4          400  \n",
       "6                   0.009666       0.162436          3          700  \n",
       "5                   0.007951       0.166789          3          600  \n",
       "10                  0.006402       0.149605          4          300  \n",
       "4                   0.006496       0.159979          3          500  \n",
       "3                   0.009105       0.158910          3          400  \n",
       "9                   0.007838       0.146728          4          200  \n",
       "2                   0.009139       0.158546          3          300  \n",
       "1                   0.008368       0.163617          3          200  \n",
       "8                   0.005850       0.155274          4          100  \n",
       "0                   0.005798       0.165897          3          100  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.sort_values(by='training_score',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>predict_training_score</th>\n",
       "      <th>predict_validation_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.012355</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.007838</td>\n",
       "      <td>0.146728</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_score  validation_score  predict_training_score  \\\n",
       "9        0.004269          0.012355                0.002659   \n",
       "\n",
       "   predict_validation_score  testing_score  max_depth  n_estimator  \n",
       "9                  0.007838       0.146728          4          200  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[temp_df.testing_score == temp_df.testing_score.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>predict_training_score</th>\n",
       "      <th>predict_validation_score</th>\n",
       "      <th>testing_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.01131</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>0.159979</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   training_score  validation_score  predict_training_score  \\\n",
       "4        0.003612           0.01131                0.003575   \n",
       "\n",
       "   predict_validation_score  testing_score  max_depth  n_estimator  \n",
       "4                  0.006496       0.159979          3          500  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df[temp_df.validation_score == temp_df.validation_score.min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = temp_df[temp_df.max_depth==3].plot.line('n_estimator','training_score',ax =ax)\n",
    "ax = temp_df[temp_df.max_depth==3].plot.line('n_estimator','validation_score',ax =ax)\n",
    "plt.show()\n",
    "fig, ax = plt.subplots()\n",
    "ax = temp_df[temp_df.max_depth==4].plot.line('n_estimator','training_score',ax =ax)\n",
    "ax = temp_df[temp_df.max_depth==4].plot.line('n_estimator','validation_score',ax =ax)\n",
    "plt.show()\n",
    "#,'validation_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kaggle score remained unchanged, this proves that our logic of test score calculation fails and there must be some value prediction which is huge which brings the average error value up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Next Steps:\n",
    "* re run the grid search and note training score, validation score and testing score. This should not only double check on test score calculation but also gives us the right hyper parameter from the training and validation perspective.\n",
    "* address the runtime error during scaling or power transform. If boxcox fails attempt a log transformation at least.\n",
    "* stratify fold testing to check if the training score & validation in the previous exercise still holds goods.\n",
    "* hyper parameter research for XGBoost\n",
    "* target variable transformation\n",
    "* best of best stack approach\n",
    "* team work stack approach\n",
    "* XGBoost as the final assesser in best of best stack approach\n",
    "* XGBoost as the final assesser in the team work starck approach\n",
    "* 3 layers in stack approach: best of best candidates in the order of their accuracy feeding on input in each case.\n",
    "* re-assess the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The grid search in the kaggle resulted in the different hyper parameter for lowest validation score. Not sure why is that ? validation is through the shuffle split. isnt 3 cross validation set sufficient ?\n",
    "\n",
    "##### Or it is a game of kfold shuffle split and stratify ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It only makes sense to move on for stacked approach and other hyper parameter tuning if we sort out the cross validation consistency issue. Otherwise, we cannot have the confidence of impact of changes in stacked approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
